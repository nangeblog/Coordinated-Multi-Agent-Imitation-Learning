{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sam/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/sam/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, TimeDistributed, BatchNormalization\n",
    "from keras.layers import LSTM, GRU\n",
    "from keras.optimizers import RMSprop, Adagrad, Adam, SGD\n",
    "#from keras.models import load_model\n",
    "import keras.backend as K\n",
    "\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob, os, sys, math, warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import copy, time, glob, os, sys\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"]=\"3\"\n",
    "\n",
    "# customized ftns \n",
    "from helpers import *\n",
    "from utilities import *\n",
    "from model import *\n",
    "# ---------------------------------------------------------\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "warnings.filterwarnings('ignore')\n",
    "# warnings.filterwarnings(action='once')\n",
    "# ---------------------------------------------------------\n",
    "# directories\n",
    "main_dir = '../'\n",
    "game_dir = main_dir+'data/'\n",
    "Data = LoadData(main_dir, game_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw events shape: (231, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>end_time_left</th>\n",
       "      <th>home</th>\n",
       "      <th>moments</th>\n",
       "      <th>orig_events</th>\n",
       "      <th>playbyplay</th>\n",
       "      <th>quarter</th>\n",
       "      <th>start_time_left</th>\n",
       "      <th>visitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>702.31</td>\n",
       "      <td>{'abbreviation': 'CHI', 'players': [{'playerid...</td>\n",
       "      <td>[[1, 1451351428029, 708.28, 12.78, None, [[-1,...</td>\n",
       "      <td>[0]</td>\n",
       "      <td>GAME_ID  EVENTNUM  EVENTMSGTYPE  EVENTMS...</td>\n",
       "      <td>1</td>\n",
       "      <td>708.28</td>\n",
       "      <td>{'abbreviation': 'TOR', 'players': [{'playerid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>686.28</td>\n",
       "      <td>{'abbreviation': 'CHI', 'players': [{'playerid...</td>\n",
       "      <td>[[1, 1451351428029, 708.28, 12.78, None, [[-1,...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>GAME_ID  EVENTNUM  EVENTMSGTYPE  EVENTMS...</td>\n",
       "      <td>1</td>\n",
       "      <td>708.28</td>\n",
       "      <td>{'abbreviation': 'TOR', 'players': [{'playerid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>668.42</td>\n",
       "      <td>{'abbreviation': 'CHI', 'players': [{'playerid...</td>\n",
       "      <td>[[1, 1451351444029, 692.25, 12.21, None, [[-1,...</td>\n",
       "      <td>[2, 3]</td>\n",
       "      <td>GAME_ID  EVENTNUM  EVENTMSGTYPE  EVENTMS...</td>\n",
       "      <td>1</td>\n",
       "      <td>692.25</td>\n",
       "      <td>{'abbreviation': 'TOR', 'players': [{'playerid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   end_time_left                                               home  \\\n",
       "0         702.31  {'abbreviation': 'CHI', 'players': [{'playerid...   \n",
       "1         686.28  {'abbreviation': 'CHI', 'players': [{'playerid...   \n",
       "2         668.42  {'abbreviation': 'CHI', 'players': [{'playerid...   \n",
       "\n",
       "                                             moments orig_events  \\\n",
       "0  [[1, 1451351428029, 708.28, 12.78, None, [[-1,...         [0]   \n",
       "1  [[1, 1451351428029, 708.28, 12.78, None, [[-1,...         [1]   \n",
       "2  [[1, 1451351444029, 692.25, 12.21, None, [[-1,...      [2, 3]   \n",
       "\n",
       "                                          playbyplay  quarter  \\\n",
       "0        GAME_ID  EVENTNUM  EVENTMSGTYPE  EVENTMS...        1   \n",
       "1        GAME_ID  EVENTNUM  EVENTMSGTYPE  EVENTMS...        1   \n",
       "2        GAME_ID  EVENTNUM  EVENTMSGTYPE  EVENTMS...        1   \n",
       "\n",
       "   start_time_left                                            visitor  \n",
       "0           708.28  {'abbreviation': 'TOR', 'players': [{'playerid...  \n",
       "1           708.28  {'abbreviation': 'TOR', 'players': [{'playerid...  \n",
       "2           692.25  {'abbreviation': 'TOR', 'players': [{'playerid...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%time\n",
    "game_id = '0021500463'\n",
    "game_data = Data.load_game(game_id)\n",
    "events_df = pd.DataFrame(game_data['events'])\n",
    "print('raw events shape:', events_df.shape)\n",
    "events_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get some suplementary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# play id to play roles/positions\n",
    "id_role = id_position(events_df)\n",
    "check_game_roles_duplicates(id_role)\n",
    "\n",
    "# its possible that F has similar role as G-f or F-G, we create empty slots to ensure meta order\n",
    "# ddentify defending and offending runs (this is included in process_moments)\n",
    "court_index = Data.load_csv('./meta_data/court_index.csv')\n",
    "court_index = dict(zip(court_index.game_id, court_index.court_position))\n",
    "\n",
    "# home and visitor ids\n",
    "homeid = events_df.loc[0].home['teamid']\n",
    "awayid = events_df.loc[0].visitor['teamid']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-process \n",
    "filter events, subsample frames, add velocity, reorder moments, re-arrange team order\n",
    "shot clock, filter out event with short moments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After filtering events has shape: (134, 8)\n",
      "Final number of events: 165\n"
     ]
    }
   ],
   "source": [
    "# filter out actions except 1: Make, 2: Miss, 4: Rebound, 6:Personal Foul, 7:Violation\n",
    "use_event = [1, 2, 4, 6, 7]\n",
    "discard_event = [3, 5, 8, 9, 10, 12, 13, 18]\n",
    "events = filter_event_type(events_df, discard_event)\n",
    "print('After filtering events has shape:', events.shape)\n",
    "# break up sequences at 24secs shot clock point (or irregular case, e.g. out of bound maybe),\n",
    "# and obtain the game data\n",
    "subsample_factor = 0\n",
    "single_game, single_game_balls = get_game_data_ra(events, court_index, game_id, \n",
    "                                                  event_threshold=10, subsample_factor=subsample_factor)\n",
    "print('Final number of events:', len(single_game))\n",
    "\n",
    "# get player velocity\n",
    "fs_base = 1./25 # 1/25 sec/frame   or  25 frames/sec\n",
    "fs = fs_base * subsample_factor if subsample_factor != 0 else fs_base\n",
    "single_game = [get_velocity(i, fs, mode=1) for i in single_game]\n",
    "n_events = len(single_game)\n",
    "\n",
    "# get basketball velocity\n",
    "single_game_balls = [np.concatenate([i[:-1, :], get_velocity(i, fs, mode=0)], axis=1) for i in single_game_balls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37, 40)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_game[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37, 6)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_game_balls[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Role assignment and reorder moment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# first prepare data\n",
    "n_defend = 5\n",
    "n_offend = 5\n",
    "n_ind = 4\n",
    "\n",
    "# length for each moment\n",
    "event_lengths = np.array([len(i) for i in single_game])\n",
    "# repeat the event_lengths 5 times in order to match the unstack later on with moments\n",
    "event_lengths_repeat = np.concatenate([event_lengths for _ in range(n_defend)], axis=0)\n",
    "# all the moments\n",
    "all_moments = np.concatenate(single_game, axis=0)\n",
    "all_moments_vel = np.concatenate(single_game, axis=0) # vel\n",
    "# we only need the first 5 players x,y coordindates\n",
    "# defend\n",
    "all_defend_moments = all_moments[:, :n_ind*n_defend]\n",
    "# offend\n",
    "all_offend_moments = all_moments[:, n_ind*n_offend:]\n",
    "\n",
    "# flattened\n",
    "all_defend_moments_ = np.concatenate([all_defend_moments[:, i:i+n_ind] for i in range(0, n_ind*n_defend, n_ind)], axis=0)\n",
    "all_offend_moments_ = np.concatenate([all_offend_moments[:, i:i+n_ind] for i in range(0, n_ind*n_offend, n_ind)], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create hmm model\n",
    "n_comp = 7\n",
    "n_mix = None\n",
    "RA = RoleAssignment(n_iter=50,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         1    -1526457.8325             +nan\n",
      "         2    -1268924.5854     +257533.2471\n",
      "         3    -1200828.2524      +68096.3330\n",
      "         4    -1172055.6233      +28772.6291\n",
      "         5    -1168202.8601       +3852.7632\n",
      "         6    -1166918.4365       +1284.4236\n",
      "         7    -1166079.8787        +838.5578\n",
      "         8    -1165555.5242        +524.3545\n",
      "         9    -1165269.0194        +286.5048\n",
      "        10    -1165082.1474        +186.8720\n",
      "        11    -1164971.9147        +110.2327\n",
      "        12    -1164914.3671         +57.5477\n",
      "        13    -1164891.1977         +23.1694\n",
      "        14    -1164881.8610          +9.3367\n",
      "        15    -1164877.5057          +4.3553\n",
      "        16    -1164875.3154          +2.1902\n",
      "        17    -1164874.1176          +1.1978\n",
      "        18    -1164873.3956          +0.7220\n",
      "        19    -1164872.9145          +0.4811\n",
      "        20    -1164872.5633          +0.3512\n",
      "        21    -1164872.2874          +0.2759\n",
      "        22    -1164872.0588          +0.2287\n",
      "        23    -1164871.8621          +0.1966\n",
      "        24    -1164871.6884          +0.1737\n",
      "        25    -1164871.5309          +0.1575\n",
      "        26    -1164871.3832          +0.1477\n",
      "        27    -1164871.2383          +0.1449\n",
      "        28    -1164871.0897          +0.1486\n",
      "        29    -1164870.9373          +0.1523\n",
      "        30    -1164870.7939          +0.1435\n",
      "        31    -1164870.6772          +0.1167\n",
      "        32    -1164870.5929          +0.0843\n",
      "        33    -1164870.5329          +0.0600\n",
      "        34    -1164870.4876          +0.0453\n",
      "        35    -1164870.4510          +0.0366\n",
      "        36    -1164870.4200          +0.0310\n",
      "        37    -1164870.3930          +0.0270\n",
      "        38    -1164870.3692          +0.0238\n",
      "        39    -1164870.3481          +0.0212\n",
      "        40    -1164870.3291          +0.0190\n",
      "        41    -1164870.3120          +0.0171\n",
      "        42    -1164870.2965          +0.0155\n",
      "        43    -1164870.2823          +0.0142\n",
      "        44    -1164870.2693          +0.0130\n",
      "        45    -1164870.2572          +0.0120\n",
      "        46    -1164870.2461          +0.0112\n",
      "        47    -1164870.2356          +0.0104\n",
      "        48    -1164870.2259          +0.0098\n",
      "         1    -1677542.2184             +nan\n",
      "         2    -1397223.2042     +280319.0142\n",
      "         3    -1318761.2083      +78461.9960\n",
      "         4    -1292368.8909      +26392.3173\n",
      "         5    -1284579.2792       +7789.6118\n",
      "         6    -1282959.7569       +1619.5222\n",
      "         7    -1281825.3392       +1134.4178\n",
      "         8    -1281054.7844        +770.5548\n",
      "         9    -1280509.7090        +545.0753\n",
      "        10    -1280193.0207        +316.6883\n",
      "        11    -1280023.9156        +169.1051\n",
      "        12    -1279896.2449        +127.6707\n",
      "        13    -1279769.0750        +127.1699\n",
      "        14    -1279627.7735        +141.3015\n",
      "        15    -1279500.9772        +126.7963\n",
      "        16    -1279378.2119        +122.7652\n",
      "        17    -1279303.6785         +74.5334\n",
      "        18    -1279263.6661         +40.0124\n",
      "        19    -1279241.8657         +21.8004\n",
      "        20    -1279229.2685         +12.5972\n",
      "        21    -1279221.7699          +7.4986\n",
      "        22    -1279216.8560          +4.9139\n",
      "        23    -1279213.1648          +3.6912\n",
      "        24    -1279210.0003          +3.1646\n",
      "        25    -1279207.0391          +2.9611\n",
      "        26    -1279204.2209          +2.8182\n",
      "        27    -1279201.6883          +2.5326\n",
      "        28    -1279199.6302          +2.0582\n",
      "        29    -1279198.1007          +1.5294\n",
      "        30    -1279197.0132          +1.0875\n",
      "        31    -1279196.2382          +0.7750\n",
      "        32    -1279195.6674          +0.5709\n",
      "        33    -1279195.2244          +0.4430\n",
      "        34    -1279194.8571          +0.3672\n",
      "        35    -1279194.5295          +0.3276\n",
      "        36    -1279194.2173          +0.3123\n",
      "        37    -1279193.9077          +0.3096\n",
      "        38    -1279193.6016          +0.3061\n",
      "        39    -1279193.3114          +0.2902\n",
      "        40    -1279193.0517          +0.2597\n",
      "        41    -1279192.8299          +0.2218\n",
      "        42    -1279192.6451          +0.1848\n",
      "        43    -1279192.4922          +0.1529\n",
      "        44    -1279192.3654          +0.1268\n",
      "        45    -1279192.2596          +0.1058\n",
      "        46    -1279192.1707          +0.0889\n",
      "        47    -1279192.0954          +0.0753\n",
      "        48    -1279192.0311          +0.0643\n",
      "        49    -1279191.9758          +0.0554\n",
      "        50    -1279191.9276          +0.0482\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "defend_state_sequence_, defend_means, defend_covs, _ = RA.train_hmm(all_defend_moments_, event_lengths_repeat, n_comp, n_mix)\n",
    "offend_state_sequence_, offend_means, offend_covs, _ = RA.train_hmm(all_offend_moments_, event_lengths_repeat, n_comp, n_mix)\n",
    "# get role orders\n",
    "_, defend_roles = RA.assign_roles(all_defend_moments_, all_defend_moments, defend_means, event_lengths)\n",
    "_, offend_roles = RA.assign_roles(all_offend_moments_, all_offend_moments, offend_means, event_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "defend_pos_vel = order_moment_ra([i[:, :n_ind*5] for i in single_game], defend_roles)\n",
    "offend_pos_vel = order_moment_ra([i[:, n_ind*5:] for i in single_game], offend_roles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37, 6)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_game_balls[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37, 28)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "defend_pos_vel[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11.15334, 21.35529, -4.02675, ..., 11.67492, -0.2985 ,  0.495  ],\n",
       "       [10.99227, 21.31452, -2.59725, ..., 11.69472, -0.29875,  0.7705 ],\n",
       "       [10.88838, 21.3161 , -2.02775, ..., 11.72554, -0.30525,  1.0805 ],\n",
       "       ...,\n",
       "       [ 8.37199, 23.28826, -5.046  , ..., 17.59439,  1.261  ,  0.8865 ],\n",
       "       [ 8.17015, 23.48841, -4.9075 , ..., 17.62985,  0.03675,  0.445  ],\n",
       "       [ 7.97385, 23.71319, -4.1805 , ..., 17.64765, -0.16425,  0.76475]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "defend_pos_vel[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# concatenate defend, offend roles pos and velocity and the basketball pos and vel\n",
    "single_game = [np.concatenate([defend_pos_vel[i], offend_pos_vel[i], single_game_balls[i]], axis=1) for i in range(n_events)]\n",
    "# single_game = [np.concatenate([defend_pos_vel[i], offend_pos_vel[i]], axis=1) for i in range(n_events)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37, 62)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_game[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_roles = [np.concatenate([defend_roles[i], offend_roles[i]], axis=1) for i in range(len(single_game))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37, 10)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_roles[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_roles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show the plot, for the sake of comparison with processed moment later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot = PlotGame(game_id, main_dir, game_dir)\n",
    "# # for i in range(plotn): \n",
    "# Plot.load_moment2img(game_data, event_number=0, moment_number=0, return_img=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # manual plot check\n",
    "# plot_check(single_game, plt_ind=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create label, train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sequence_length = 50\n",
    "overlap = 25\n",
    "# pad short sequence and chunk long sequence with overlaps\n",
    "train, target = get_sequences(single_game, sequence_length, overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create train and test set\n",
    "p = 0.8 # train percentage\n",
    "divider = int(len(train)*p)\n",
    "train_game, test_game = train[:divider], train[divider:]\n",
    "train_target, test_target = target[:divider], target[divider:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(632, 158)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_game), len(test_game)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49, 62)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_game[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build graph and starts training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hyper-parameters\n",
    "# num_layers = 2\n",
    "state_size = 128\n",
    "batch_size = 32\n",
    "dimx = 62 # 4(x,y,vx,vy)*14 + 6 = 62\n",
    "dimy = 2\n",
    "learning_rate = 0.001\n",
    "n_epoch = int(1e3)\n",
    "true_seq_len = sequence_length-1\n",
    "\n",
    "init_model = Sequential()\n",
    "init_model.add(LSTM(state_size, batch_input_shape=(batch_size, true_seq_len, dimx), return_sequences=True,  stateful=True))\n",
    "init_model.add(LSTM(state_size, return_sequences=False,stateful=True))\n",
    "init_model.add(Dense (2))\n",
    "init_model.add(Activation('linear'))\n",
    "init_model.compile(loss='mse', optimizer='rmsprop')\n",
    "init_model.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # For a mean squared error regression problem\n",
    "# # rmsprop = RMSprop(lr=1e-4)\n",
    "# adam = Adam(lr=1e-5, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "# # sgd = SGD(lr=1e-4, momentum=0.99, decay=0.0, nesterov=True)\n",
    "\n",
    "# # model.compile(optimizer=rmsprop, loss='mse', metrics=['mae'])\n",
    "# # model.compile(optimizer=adam, loss='mse', metrics=['mae'])\n",
    "# model.compile(optimizer=sgd, loss='mse', metrics=['mae'])\n",
    "\n",
    "# # add early stopping, reducing learning rate and visualization using tensorboard \n",
    "# early_stop = EarlyStopping(monitor='val_loss', patience=10, verbose=1)\n",
    "# reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=5, verbose=1)\n",
    "# visualize = TensorBoard(log_dir='./train_logs/')#, histogram_freq=1, write_graph=True)#, write_grads=True)\n",
    "\n",
    "# # start training\n",
    "# t1 = time.time()\n",
    "# history = model.fit(train_data, train_target*scaling,\n",
    "#                     batch_size=128,\n",
    "#                     epochs=n_epochs,\n",
    "#                     verbose=1,\n",
    "#                     validation_data=(val_data, val_target*scaling),\n",
    "#                     callbacks=[early_stop, reduce_lr, visualize])\n",
    "# t2 = time.time()\n",
    "# print(\"Done training, used {0:.2f} min\".format((t2-t1)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Horizon 0 ==========\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected activation_1 to have 2 dimensions, but got array with shape (32, 49, 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-703fd36e24b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mtrain_xi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_yi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#             print(np.array(train_xi).shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_xi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_yi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mn_train_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mtrain_step\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sam/anaconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/home/sam/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1628\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1629\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1630\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1631\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1632\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sam/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m   1478\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1479\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1480\u001b[0;31m                                     exception_prefix='target')\n\u001b[0m\u001b[1;32m   1481\u001b[0m         sample_weights = _standardize_sample_weights(sample_weight,\n\u001b[1;32m   1482\u001b[0m                                                      self._feed_output_names)\n",
      "\u001b[0;32m/home/sam/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    111\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    114\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected activation_1 to have 2 dimensions, but got array with shape (32, 49, 2)"
     ]
    }
   ],
   "source": [
    "horizon = [0]\n",
    "for k in horizon:\n",
    "    print('Horizon {0:} {1:}'.format(k, '='*10))\n",
    "\n",
    "    for epoch in range(n_epoch):\n",
    "        epoch_loss =0.\n",
    "        # number of train batches\n",
    "        n_train_batch = len(train_game)//batch_size\n",
    "        t1 = time.time()\n",
    "        for batch in iterate_minibatches(train_game, train_target, batch_size, shuffle=False):\n",
    "            train_xi, train_yi = batch\n",
    "#             print(np.array(train_xi).shape)\n",
    "            l = init_model.fit(np.array(train_xi), np.array(train_yi))\n",
    "            epoch_loss += l/n_train_batch\n",
    "            train_step += 1\n",
    "        # print out info\n",
    "        if epoch%printn ==0:\n",
    "            # number of validation batches\n",
    "            n_val_batch = len(test_game)//batch_size\n",
    "            t2 = time.time()\n",
    "            valid_loss = 0\n",
    "            for test_batch in iterate_minibatches(test_game, test_target, batch_size, shuffle=False):\n",
    "                val_xi, val_yi = test_batch\n",
    "                l = init_model.fit(np.array(val_xi), np.array(val_yi))\n",
    "                valid_loss += val_l/n_val_batch\n",
    "                valid_step += printn\n",
    "            print('Epoch {0:<4d} | loss: {1:<8.2f} | time took: {2:<.2f}s '\n",
    "                  '| validation loss: {3:<8.2f}'.format(epoch, epoch_loss, (t2-t1), valid_loss))\n",
    "                \n",
    "\n",
    "t_end = time.time()\n",
    "print('Total time took: {0:<.2f}hrs'.format((time.time()-t_int)/60/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "# use training start time as the unique naming\n",
    "train_time = datetime.now().strftime('%Y_%m_%d_%H_%M_%S')\n",
    "logs_path = './train_logs/'\n",
    "\n",
    "# hyper-parameters\n",
    "# num_layers = 2\n",
    "state_size = 128\n",
    "batch_size = 32\n",
    "dimx = 62 # 4(x,y,vx,vy)*14 + 6 = 62\n",
    "dimy = 2\n",
    "learning_rate = 0.001\n",
    "n_epoch = int(1e3)\n",
    "true_seq_len = sequence_length-1\n",
    "\n",
    "# lstm cells\n",
    "lstm1 = tf.contrib.rnn.BasicLSTMCell(state_size, forget_bias=1.)\n",
    "# lstm1 = tf.nn.rnn_cell.DropoutWrapper(lstm1, output_keep_prob=0.8)\n",
    "\n",
    "lstm2 = tf.contrib.rnn.BasicLSTMCell(state_size, forget_bias=1.)\n",
    "# lstm2 = tf.nn.rnn_cell.DropoutWrapper(lstm2, output_keep_prob=0.8)\n",
    "\n",
    "lstm_cell = tf.contrib.rnn.MultiRNNCell([lstm1, lstm2])\n",
    "\n",
    "# a single lstm layer\n",
    "# lstm_cell = tf.contrib.rnn.BasicLSTMCell(state_size, forget_bias=1.)\n",
    "# lstm_cell = tf.nn.rnn_cell.DropoutWrapper(lstm_cell, output_keep_prob=0.7)\n",
    "\n",
    "# input placeholders\n",
    "h = tf.placeholder(tf.int32)\n",
    "seq_len = tf.placeholder(tf.int32)\n",
    "# X = tf.placeholder(tf.float32, [batch_size, None, dimx], name = 'train_input')\n",
    "# Y = tf.placeholder(tf.float32, [batch_size, None, dimy], name = 'train_label')\n",
    "X = tf.placeholder(tf.float32, [batch_size, true_seq_len, dimx], name = 'train_input')\n",
    "Y = tf.placeholder(tf.float32, [batch_size, true_seq_len, dimy], name = 'train_label')\n",
    "\n",
    "# rnn structure\n",
    "output, last_states = dynamic_raw_rnn(cell = lstm_cell, \n",
    "                                  input_ = X,\n",
    "                                  batch_size = batch_size,\n",
    "                                  seq_length = seq_len,\n",
    "                                  horizon = h,\n",
    "                                  output_dim = dimy)\n",
    "\n",
    "# output as the prediction\n",
    "pred = output\n",
    "\n",
    "# tensorboard's graph visualization more convenient\n",
    "with tf.name_scope('MSEloss'):\n",
    "    # loss (also add regularization on params)\n",
    "    tv = tf.trainable_variables()\n",
    "    # l2 weight loss\n",
    "#     regularization_cost = tf.reduce_sum([tf.nn.l2_loss(v) for v in tv])\n",
    "    # l1 loss\n",
    "    l1_regularizer = tf.contrib.layers.l1_regularizer(scale=0.005, scope=None)\n",
    "    regularization_cost = tf.contrib.layers.apply_regularization(l1_regularizer, tv)\n",
    "\n",
    "    loss = tf.losses.mean_squared_error(Y, pred) + regularization_cost\n",
    "    \n",
    "    # no weight loss\n",
    "#     loss = tf.losses.mean_squared_error(Y, pred)\n",
    "\n",
    "with tf.name_scope('Adam'):\n",
    "    # optimzier\n",
    "    opt = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "    \n",
    "# initialize variables\n",
    "init = tf.global_variables_initializer()\n",
    "# create a summary to monitor cost tensor\n",
    "train_summary = tf.summary.scalar(\"TrainMSEloss\", loss)\n",
    "valid_summary = tf.summary.scalar(\"ValidMSEloss\", loss)\n",
    "# # Merge all summaries into a single op\n",
    "# merged_summary_op = tf.summary.merge_all()\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "# session\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "# initializing the variables\n",
    "sess.run(init)\n",
    "# op to write logs to Tensorboard\n",
    "train_writer = tf.summary.FileWriter(logs_path+'/train'+train_time, graph=tf.get_default_graph())\n",
    "valid_writer = tf.summary.FileWriter(logs_path+'/valid'+train_time, graph=tf.get_default_graph())\n",
    "\n",
    "# ===============================================================================================\n",
    "\n",
    "# start training\n",
    "printn = 100    # how many epochs we print\n",
    "# look-ahead horizon\n",
    "horizon = [0]\n",
    "t_int = time.time()\n",
    "train_step = 0\n",
    "valid_step = 0\n",
    "for k in horizon:\n",
    "    print('Horizon {0:} {1:}'.format(k, '='*10))\n",
    "\n",
    "    for epoch in range(n_epoch):\n",
    "        epoch_loss =0.\n",
    "        # number of train batches\n",
    "        n_train_batch = len(train_game)//batch_size\n",
    "        t1 = time.time()\n",
    "        for batch in iterate_minibatches(train_game, train_target, batch_size, shuffle=False):\n",
    "            train_xi, train_yi = batch\n",
    "            p, l, _, train_sum = sess.run([output, loss, opt, train_summary], \n",
    "                                          feed_dict={X: train_xi, Y: train_yi, \n",
    "                                                     seq_len:true_seq_len,\n",
    "                                                     h: k})\n",
    "            train_writer.add_summary(train_sum, train_step)\n",
    "            epoch_loss += l/n_train_batch\n",
    "            train_step += 1\n",
    "        # print out info\n",
    "        if epoch%printn ==0:\n",
    "            # number of validation batches\n",
    "            n_val_batch = len(test_game)//batch_size\n",
    "            t2 = time.time()\n",
    "            valid_loss = 0\n",
    "            for test_batch in iterate_minibatches(test_game, test_target, batch_size, shuffle=False):\n",
    "                val_xi, val_yi = test_batch\n",
    "                val_l, valid_sum = sess.run([loss, valid_summary], \n",
    "                                            feed_dict={X: val_xi, Y: val_yi, \n",
    "                                                       seq_len:true_seq_len,\n",
    "                                                       h: k})\n",
    "\n",
    "                valid_writer.add_summary(valid_sum, valid_step)\n",
    "                valid_loss += val_l/n_val_batch\n",
    "                valid_step += printn\n",
    "            print('Epoch {0:<4d} | loss: {1:<8.2f} | time took: {2:<.2f}s '\n",
    "                  '| validation loss: {3:<8.2f}'.format(epoch, epoch_loss, (t2-t1), valid_loss))\n",
    "                \n",
    "\n",
    "t_end = time.time()\n",
    "print('Total time took: {0:<.2f}hrs'.format((time.time()-t_int)/60/60))\n",
    "\n",
    "# save model\n",
    "saver.save(sess, './models/test-model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Check model on train set (per player)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# use while loop to make sure the \n",
    "train_batches = get_minibatches(train_game, train_target, batch_size, shuffle=False)\n",
    "\n",
    "check_ind = np.random.randint(0, len(train_game)//batch_size)\n",
    "print('rand checking index: {0:} out of {1:}'.format(check_ind, len(train_game)//batch_size))\n",
    "\n",
    "input_xi, output_yi = train_batches\n",
    "y_pred = sess.run([output], feed_dict={X: input_xi[check_ind], seq_len:true_seq_len, h: 4})#, Y: train_yi, h:2})\n",
    "y_true = output_yi[check_ind]\n",
    "    \n",
    "y_pred = y_pred[0][0].reshape(-1,2)\n",
    "y_true = y_true[0].reshape(-1,2)\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "for k in range(0, len(y_pred)):\n",
    "    plt.plot(y_pred[:, 0][k], y_pred[:, 1][k], linestyle=\"None\", marker=\"o\", markersize=k, color='g')\n",
    "    plt.plot(y_true[:, 0][k], y_true[:, 1][k], linestyle=\"None\", marker=\"o\", markersize=k, color='b')\n",
    "\n",
    "plt.plot(y_pred[:, 0], y_pred[:, 1],'g', y_true[:,0], y_true[:,1], 'b')#, pred_train[:, 0], pred_train[:, 1])\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(train_game)//batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check model on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use while loop to make sure the \n",
    "test_batches = get_minibatches(test_game, test_target, batch_size, shuffle=False)\n",
    "\n",
    "check_ind = np.random.randint(0, len(test_game)//batch_size)\n",
    "print('rand checking index: {0:} out of {1:}'.format(check_ind, len(test_game)//batch_size))\n",
    "\n",
    "input_xi, output_yi = test_batches\n",
    "y_pred = sess.run([output], feed_dict={X: input_xi[check_ind], seq_len:true_seq_len, h: 1})#, Y: train_yi, h:2})\n",
    "y_true = output_yi[check_ind]\n",
    "    \n",
    "y_pred = y_pred[0][0].reshape(-1,2)\n",
    "y_true = y_true[0].reshape(-1,2)\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "for k in range(0, len(y_pred)):\n",
    "    plt.plot(y_pred[:, 0][k], y_pred[:, 1][k], linestyle=\"None\", marker=\"o\", markersize=k, color='g')\n",
    "    plt.plot(y_true[:, 0][k], y_true[:, 1][k], linestyle=\"None\", marker=\"o\", markersize=k, color='b')\n",
    "\n",
    "plt.plot(y_pred[:, 0], y_pred[:, 1],'g', y_true[:,0], y_true[:,1], 'b')#, pred_train[:, 0], pred_train[:, 1])\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To do:\n",
    "\n",
    "    - 1) Regularize the lstm\n",
    "    - 2) Figure out why there are blanks in the testing\n",
    "    - 3) may consider to collect those left out from the process of creating batches\n",
    "    - 4) related to 3), seq_len = 3 may create null batches \n",
    "\n",
    "    - Split data to defending and offending, as the model for e.g. forward role in deffending and offending should be pretty different. Remove particular events, like free-throw etc.\n",
    "    \n",
    "    - We can use the shot clock as an indicator of when the offending and defending switches.\n",
    "    \n",
    "    - The cameras oprate at 25 frames per second, so in order to learn realistic motions, either we sample the 25 frames, or extend the horizon to 50 for example or even longer(this might be too computationally heavy and model would probably drift a lot).\n",
    "    \n",
    "    - At the moment if we don't have defending or offending sepearted, at least we need to break down the sequences from the 24 secs shot clock, since it usually stands for a change in game state. (note: shot clock sometimes is None)\n",
    "    \n",
    "    - Add tensorboard visualization. Add validation performance (maybe, it would take longer). \n",
    "      tensorboard --logdir=./train_logs\n",
    "      \n",
    "    - Start thinking about 1) joint training 2) Hidden structure 3) Smooth learning\n",
    "    - from each sample to next sample theres not much change, subsample them "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Questions\n",
    "\n",
    "    * After a team scored and they go back to get ready for defense, is the going back trajectory pretty much random?\n",
    "    * Do player swap roles during the play? e.g. a forward swapped to a guard, is the forward roles a lot different from gaurds these day? (i.e. can you differentaite a player plaing forward from guard from the game) If yes, then the hidden structure learning/sequencing is necessary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
