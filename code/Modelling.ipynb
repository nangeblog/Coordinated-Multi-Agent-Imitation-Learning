{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sam/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/home/sam/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.ops.rnn import _transpose_batch_time\n",
    "\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import copy, time, glob, os, sys\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"]=\"3\"\n",
    "\n",
    "# customized ftns \n",
    "from helpers import *\n",
    "from utilities import LoadData, PlotGame, make_video\n",
    "from model import rnn_horizon\n",
    "# ---------------------------------------------------------\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# directories\n",
    "main_dir = '../'\n",
    "game_dir = main_dir+'data/'\n",
    "Data = LoadData(main_dir, game_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "game_id = '0021500463'\n",
    "game_data = Data.load_game(game_id)\n",
    "events_df = pd.DataFrame(game_data['events'])\n",
    "print('raw events shape:', events_df.shape)\n",
    "events_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get some suplementary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# play id to play roles/positions\n",
    "id_role = id_position(events_df)\n",
    "check_game_roles_duplicates(id_role)\n",
    "\n",
    "# we will use this fixed order as the role order\n",
    "roles = ['F', 'G', 'C-F', 'G-F', 'F-G', 'C', 'F-C']\n",
    "role_order = {'F': 0, 'G':4, 'C-F':1, 'G-F':3, 'F-G':3, 'C':2, 'F-C':1}\n",
    "\n",
    "# its possible that F has similar role as G-f or F-G, we create empty slots to ensure meta order\n",
    "# ddentify defending and offending runs (this is included in process_moments)\n",
    "court_index = Data.load_csv('./meta_data/court_index.csv')\n",
    "court_index = dict(zip(court_index.game_id, court_index.court_position))\n",
    "\n",
    "# home and visitor ids\n",
    "homeid = events_df.loc[0].home['teamid']\n",
    "awayid = events_df.loc[0].visitor['teamid']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out actions except 1: Make, 2: Miss, 4: Rebound, 6:Personal Foul, 7:Violation\n",
    "use_event = [1, 2, 4, 6, 7]\n",
    "discard_event = [3, 5, 8, 9, 10, 12, 13, 18]\n",
    "events = filter_event_type(events_df, discard_event)\n",
    "print('After filtering events has shape:', events.shape)\n",
    "# break up sequences at 24secs shot clock point (or irregular case, e.g. out of bound maybe),\n",
    "# and obtain the game data\n",
    "single_game = get_game_data(events, id_role, role_order, court_index, game_id, \n",
    "                            event_threshold=10, subsample_factor=2)\n",
    "print('Final number of events:', len(single_game))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_game[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show the plot, for the sake of comparison with processed moment later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Plot = PlotGame(game_id, main_dir, game_dir)\n",
    "# for i in range(plotn): \n",
    "Plot.load_moment2img(game_data, event_number=0, moment_number=0, return_img=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cerate a simple plot shows the trajectory\n",
    "g = single_game[0]\n",
    "plt.figure(figsize=(5,7))\n",
    "extreme = 3 \n",
    "# create color scheme\n",
    "c = ['b']*30 + ['r']*30\n",
    "for i in range(0, extreme*10*2, 2): # extreme=3, palyers=10, x,y=2\n",
    "    x_i, y_i = g[:, i], g[:, i+1]\n",
    "    if sum(x_i) !=0 and sum(y_i) != 0:\n",
    "        for k in range(0, len(x_i)):\n",
    "            plt.plot(x_i[k], y_i[k], linestyle=\"None\", marker=\"o\", markersize=k/3, color=c[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create label, train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lets first predict role F (ignored the extreme)\n",
    "# game_target = [np.roll(i[:, :2], -1, axis=0)[:-1, :] for i in single_game] # drop the last row as the rolled-back is not real\n",
    "# game_data = [i[:-1, :] for i in single_game] # also need to drop the last element as it does not have next timestep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# game_lens = [len(i) for i in game_data]\n",
    "# _ = plt.hist(game_lens, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import collections\n",
    "# counter=collections.Counter(game_lens)\n",
    "# counter.most_common(5)\n",
    "sequence_length = 50\n",
    "overlap = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# game_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = []\n",
    "target = []\n",
    "for i in single_game:\n",
    "    i_len = len(i)\n",
    "    if i_len < sequence_length:\n",
    "        sequences = np.pad(np.array(i), [(0, sequence_length-i_len), (0,0)], mode='constant')\n",
    "        targets = [np.roll(sequences[:, :2], -1, axis=0)[:-1, :]]\n",
    "        sequences = [sequences[:-1, :]]\n",
    "#         R.append()\n",
    "    else:\n",
    "        # if theres space for having desired overlap\n",
    "#         if sequence_length - (i_len - sequence_length) <= overlap:\n",
    "#             n_seq = i_len//sequence_length\n",
    "#             R += [i[j*sequence_length:(j+1)*sequence_length] for j in range(n_seq)]\n",
    "#         else:\n",
    "#             R += [i[:sequence_length], i[-sequence_length:]]\n",
    "\n",
    "        # https://stackoverflow.com/questions/48381870/a-better-way-to-split-a-sequence-in-chunks-with-overlaps\n",
    "        sequences = [np.array(i[-sequence_length:]) if j + sequence_length > i_len-1 else np.array(i[j:j+sequence_length]) \\\n",
    "             for j in range(0, i_len-overlap, sequence_length-overlap)]\n",
    "        targets = [np.roll(k[:, :2], -1, axis=0)[:-1, :] for k in sequences] # drop the last row as the rolled-back is not real\n",
    "        sequences = [l[:-1, :] for l in sequences] \n",
    "       \n",
    "    train += sequences\n",
    "    target += targets\n",
    "# train = np.array(train)\n",
    "# target = np.array(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train and test set\n",
    "p = 0.8 # train percentage\n",
    "divider = int(len(train)*p)\n",
    "train_game, test_game = train[:divider], train[divider:]\n",
    "train_target, test_target = target[:divider], target[divider:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_game), len(test_game)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build graph and starts training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "# use training start time as the unique naming\n",
    "train_time = datetime.now().strftime('%Y_%m_%d_%H_%M_%S')\n",
    "logs_path = './train_logs/'\n",
    "\n",
    "# hyper-parameters\n",
    "# num_layers = 2\n",
    "state_size = 128\n",
    "batch_size = 64\n",
    "dimx = 67\n",
    "dimy = 2\n",
    "learning_rate = 0.001\n",
    "\n",
    "# lstm cells\n",
    "# lstm1 = tf.contrib.rnn.BasicLSTMCell(state_size, forget_bias=1.)\n",
    "# lstm1 = tf.nn.rnn_cell.DropoutWrapper(lstm1, output_keep_prob=0.8)\n",
    "\n",
    "# lstm2 = tf.contrib.rnn.BasicLSTMCell(state_size, forget_bias=1.)\n",
    "# lstm2 = tf.nn.rnn_cell.DropoutWrapper(lstm2, output_keep_prob=0.8)\n",
    "\n",
    "# lstm_cell = tf.contrib.rnn.MultiRNNCell([lstm1, lstm2])\n",
    "\n",
    "# a single lstm layer\n",
    "lstm_cell = tf.contrib.rnn.BasicLSTMCell(state_size, forget_bias=1.)\n",
    "lstm_cell = tf.nn.rnn_cell.DropoutWrapper(lstm_cell, output_keep_prob=0.7)\n",
    "\n",
    "# initial state\n",
    "initial_state = lstm_cell.zero_state(batch_size, dtype=tf.float32)\n",
    "\n",
    "# input placeholders\n",
    "h = tf.placeholder(tf.int32)\n",
    "X = tf.placeholder(tf.float32, [batch_size, None, dimx], name = 'train_input')\n",
    "Y = tf.placeholder(tf.float32, [batch_size, None, dimy], name = 'train_label')\n",
    "# rnn structure\n",
    "output, last_states = rnn_horizon(cell=lstm_cell, \n",
    "                                  initial_state=initial_state, \n",
    "                                  input_=X,\n",
    "                                  batch_size=batch_size,\n",
    "                                  seq_lengths=h,\n",
    "                                  output_dim=dimy)\n",
    "# output as the prediction\n",
    "print('output shape, last_states', output.shape, last_states)\n",
    "pred = output\n",
    "print('label shape:{0:} | output prediction shape: {1:}'.format(Y.shape, pred.shape))\n",
    "\n",
    "# tensorboard's graph visualization more convenient\n",
    "with tf.name_scope('MSEloss'):\n",
    "    # loss (also add regularization on params)\n",
    "    tv = tf.trainable_variables()\n",
    "    # l2 weight loss\n",
    "#     regularization_cost = tf.reduce_sum([tf.nn.l2_loss(v) for v in tv])\n",
    "    # l1 loss\n",
    "#     l1_regularizer = tf.contrib.layers.l1_regularizer(scale=0.005, scope=None)\n",
    "#     regularization_cost = tf.contrib.layers.apply_regularization(l1_regularizer, tv)\n",
    "\n",
    "#     loss = tf.losses.mean_squared_error(Y, pred) + regularization_cost\n",
    "    # no weight loss\n",
    "    loss = tf.losses.mean_squared_error(Y, pred)\n",
    "with tf.name_scope('Adam'):\n",
    "    # optimzier\n",
    "    opt = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "    \n",
    "# initialize variables\n",
    "init = tf.global_variables_initializer()\n",
    "# create a summary to monitor cost tensor\n",
    "train_summary = tf.summary.scalar(\"TrainMSEloss\", loss)\n",
    "valid_summary = tf.summary.scalar(\"ValidMSEloss\", loss)\n",
    "# # Merge all summaries into a single op\n",
    "# merged_summary_op = tf.summary.merge_all()\n",
    "\n",
    "\n",
    "# session\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "# initializing the variables\n",
    "sess.run(init)\n",
    "# op to write logs to Tensorboard\n",
    "train_writer = tf.summary.FileWriter(logs_path+'/train'+train_time, graph=tf.get_default_graph())\n",
    "valid_writer = tf.summary.FileWriter(logs_path+'/valid'+train_time, graph=tf.get_default_graph())\n",
    "\n",
    "# ===============================================================================================\n",
    "\n",
    "# start training\n",
    "printn = int(1e2)    # how many epochs we print\n",
    "# horizon = [2, 4, 8, 12, 16, 20, 25]\n",
    "horizon = range(1, 5)\n",
    "n_epochs = [500, 500, 1000, 1000]\n",
    "t_int = time.time()\n",
    "train_step = 0\n",
    "valid_step = 0\n",
    "for k in range(len(horizon)):\n",
    "    # look-ahead horizon\n",
    "#     seq_len = horizon[k]\n",
    "    seq_len = sequence_length - 1 # because we dropped one when creating targets\n",
    "    print('Horizon {0:} {1:}'.format(seq_len, '='*10))\n",
    "\n",
    "#     # train x\n",
    "#     train_x = copy.deepcopy([get_sequences(i, seq_len, dimx) for i in train_game])\n",
    "#     train_x = copy.deepcopy(np.concatenate(train_x, axis=0))\n",
    "#     print('train_x.shape:', train_x.shape)\n",
    "#     # train y\n",
    "#     train_y = copy.deepcopy([get_sequences(i, seq_len, dimy) for i in train_target])\n",
    "#     train_y = copy.deepcopy(np.concatenate(train_y, axis=0))\n",
    "#     print('train_y.shape:', train_y.shape)\n",
    "    \n",
    "#     # valid x\n",
    "#     val_x = copy.deepcopy([get_sequences(i, seq_len, dimx) for i in test_game])\n",
    "#     val_x = copy.deepcopy(np.concatenate(val_x, axis=0))\n",
    "#     print('valid_x.shape:', val_x.shape)\n",
    "#     # valid y\n",
    "#     val_y = copy.deepcopy([get_sequences(i, seq_len, dimy) for i in test_target])\n",
    "#     val_y = copy.deepcopy(np.concatenate(val_y, axis=0))\n",
    "#     print('valid_y.shape:', val_y.shape)\n",
    "    \n",
    "    for epoch in range(n_epochs[k]):\n",
    "        epoch_loss =0.\n",
    "        # number of train batches\n",
    "        n_train_batch = len(train_game)//batch_size\n",
    "        t1 = time.time()\n",
    "        for batch in iterate_minibatches(train_game, train_target, batch_size, shuffle=False):\n",
    "            train_xi, train_yi = batch\n",
    "            p, l, _, train_sum = sess.run([output, loss, opt, train_summary], \n",
    "                                        feed_dict={X: train_xi, Y: train_yi, h:seq_len})\n",
    "            train_writer.add_summary(train_sum, train_step)\n",
    "            epoch_loss += l/n_train_batch\n",
    "            train_step += 1\n",
    "        # print out info\n",
    "        if epoch%printn ==0:\n",
    "            # number of validation batches\n",
    "            n_val_batch = len(test_game)//batch_size\n",
    "            t2 = time.time()\n",
    "            valid_loss = 0\n",
    "            for batch in iterate_minibatches(test_game, test_target, batch_size, shuffle=False):\n",
    "                val_xi, val_yi = batch\n",
    "                val_l, valid_sum = sess.run([loss, train_summary], \n",
    "                                            feed_dict={X: val_xi, Y: val_yi, h:seq_len})\n",
    "                valid_writer.add_summary(valid_sum, valid_step)\n",
    "                valid_loss += val_l/n_val_batch\n",
    "                valid_step += printn\n",
    "            print('Epoch {0:<4d} | loss: {1:<8.2f} | time took: {2:<.2f}s '\n",
    "                  '| validation loss: {3:<8.2f}'.format(epoch, epoch_loss, (t2-t1), valid_loss))\n",
    "                \n",
    "\n",
    "t_end = time.time()\n",
    "print('Total time took: {0:<.2f}hrs'.format((time.time()-t_int)/60/60))\n",
    "# sess.close()\n",
    "# # save model\n",
    "# #Create a saver object which will save all the variables\n",
    "# saver = tf.train.Saver()\n",
    "# #save the graph\n",
    "# saver.save(sess, save_path='./models/test_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Check model on train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "check_seq_len = 3\n",
    "\n",
    "# use while loop to make sure the \n",
    "present = 0\n",
    "while present == 0:\n",
    "    check_ind = np.random.randint(0, len(train_game)-1)\n",
    "    input_x = copy.deepcopy(get_sequences(train_game[check_ind], check_seq_len, dimx))\n",
    "    output_y = copy.deepcopy(get_sequences(train_target[check_ind], check_seq_len, dimy))\n",
    "    if input_x.shape[0] >= batch_size:\n",
    "        print('check_id:', check_ind)\n",
    "        present += 1\n",
    "\n",
    "pred = []\n",
    "y_train = []\n",
    "order_x = []\n",
    "for batch in iterate_minibatches(input_x, output_y, batch_size, shuffle=False):\n",
    "    input_xi, output_yi = batch\n",
    "    p = sess.run([output], feed_dict={X: input_xi, h:check_seq_len})#, Y: train_yi, h:2})\n",
    "    pred.append(p)\n",
    "    order_x.append(input_xi)\n",
    "    y_train.append(output_yi)\n",
    "pred_train = np.array(pred).reshape(-1,2)\n",
    "y_train = np.array(y_train).reshape(-1,2)\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.plot(y_train[:,0], y_train[:,1], pred_train[:, 0], pred_train[:, 1])\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check model on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "check_seq_len = 2\n",
    "\n",
    "# use while loop to make sure the \n",
    "present = 0\n",
    "while present == 0:\n",
    "    check_ind = np.random.randint(0, len(test_game)-1)\n",
    "    # check_ind = 0\n",
    "#     print('check_id:', check_ind)\n",
    "    input_x = copy.deepcopy(get_sequences(test_game[check_ind], check_seq_len, dimx))\n",
    "#     print('input x shape >>>', input_x.shape)\n",
    "    output_y = copy.deepcopy(get_sequences(test_target[check_ind], check_seq_len, dimy))\n",
    "    if input_x.shape[0] >= batch_size:\n",
    "        print('check_id:', check_ind)\n",
    "        present += 1\n",
    "\n",
    "pred = []\n",
    "y_train = []\n",
    "order_x = []\n",
    "print(input_x.shape, output_y.shape)\n",
    "for batch in iterate_minibatches(input_x, output_y, batch_size, shuffle=False):\n",
    "    input_xi, output_yi = batch\n",
    "    p = sess.run([output], feed_dict={X: input_xi, h:check_seq_len})#, Y: train_yi, h:2})\n",
    "    pred.append(p)\n",
    "    order_x.append(input_xi)\n",
    "    y_train.append(output_yi)\n",
    "pred_train = np.array(pred).reshape(-1,2)\n",
    "y_train = np.array(y_train).reshape(-1,2)\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.plot(y_train[:,0], y_train[:,1], pred_train[:, 0], pred_train[:, 1])\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create video based off predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# events.head()\n",
    "# replace the true position with the predicted\n",
    "events_pred = events.head(1).copy()\n",
    "def replace_pos(x):\n",
    "    for i in range(len(pred_train)):\n",
    "#         print(x[i][5])\n",
    "#         print(x[i][5][2][2:4], pred_train[i])\n",
    "        x[i][5][2][2:4]=pred_train[i] \n",
    "events_pred = events_pred.moments.apply(lambda x: replace_pos(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save all moments for a specific events\n",
    "Plot = PlotGame(game_id, main_dir, game_dir)\n",
    "moments = range(len(pred_train))\n",
    "event_number = 0\n",
    "for i in moments:\n",
    "    print(i, end='\\r')\n",
    "    Plot.load_pred_moment2img(game_data, event_number, i)\n",
    "# PlotGame.load_pred_moment2img()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  so by comparing the position we know we are modelling the third position ind = 2\n",
    "# order_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare to save videos\n",
    "event_dir = game_dir + 'game' + str(game_id) + '/' + 'predevent' + str(event_number) + '/'\n",
    "video_name = event_dir + str(event_number) + '.mp4'\n",
    "print(video_name)\n",
    "images = glob.glob(event_dir + \"*.png\")\n",
    "images = sorted(images, key=lambda x: int(x.split('.')[2].split('/')[-1][4:]))\n",
    "# print(images)\n",
    "# save to video\n",
    "make_video(images, video_name, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# len(events_pred.moments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To do:\n",
    "\n",
    "    - 1) Regularize the lstm\n",
    "    - 2) Figure out why there are blanks in the testing\n",
    "    - 3) may consider to collect those left out from the process of creating batches\n",
    "    - 4) related to 3), seq_len = 3 may create null batches \n",
    "\n",
    "    - Split data to defending and offending, as the model for e.g. forward role in deffending and offending should be pretty different. Remove particular events, like free-throw etc.\n",
    "    \n",
    "    - We can use the shot clock as an indicator of when the offending and defending switches.\n",
    "    \n",
    "    - The cameras oprate at 25 frames per second, so in order to learn realistic motions, either we sample the 25 frames, or extend the horizon to 50 for example or even longer(this might be too computationally heavy and model would probably drift a lot).\n",
    "    \n",
    "    - At the moment if we don't have defending or offending sepearted, at least we need to break down the sequences from the 24 secs shot clock, since it usually stands for a change in game state. (note: shot clock sometimes is None)\n",
    "    \n",
    "    - Add tensorboard visualization. Add validation performance (maybe, it would take longer). \n",
    "      tensorboard --logdir=./train_logs\n",
    "      \n",
    "    - Start thinking about 1) joint training 2) Hidden structure 3) Smooth learning\n",
    "    - from each sample to next sample theres not much change, subsample them "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Questions\n",
    "\n",
    "    * After a team scored and they go back to get ready for defense, is the going back trajectory pretty much random?\n",
    "    * Do player swap roles during the play? e.g. a forward swapped to a guard, is the forward roles a lot different from gaurds these day? (i.e. can you differentaite a player plaing forward from guard from the game) If yes, then the hidden structure learning/sequencing is necessary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
