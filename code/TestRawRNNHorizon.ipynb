{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.ops.rnn import _transpose_batch_time\n",
    "from model import sampling_rnn\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "from helpers import get_sequences, iterate_minibatches, get_minibatches\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"]=\"3\"\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First create a simple train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a sine wave\n",
    "n_samples = int(1e3)\n",
    "min_x = 0\n",
    "max_x = 100\n",
    "x = np.linspace(min_x, max_x, n_samples)\n",
    "sinx = np.sin(x)\n",
    "# add a Gaussian noise to it\n",
    "noise_m = 1\n",
    "noise_sd = 0.5\n",
    "noise = np.random.normal(noise_m, noise_sd, n_samples)\n",
    "smooth = sinx+noise_m\n",
    "y = sinx + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.plot(x, y, x, sinx+noise_m, 'r')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split it to train and test\n",
    "slice_ind = int(n_samples*0.7)\n",
    "# clear up namings for modeling\n",
    "plot_train_x, train_original_x, plot_test_x, test_x, smooth_train_x, smooth_test_x = [x[:slice_ind], y[:slice_ind], \n",
    "                                                                             x[slice_ind:], y[slice_ind:], \n",
    "                                                                             smooth[:slice_ind], smooth[slice_ind:]]\n",
    "# # chunk it to each small window\n",
    "# seq_len = 5\n",
    "# train_x = get_sequences(train_original_x, seq_len, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So we have observed that the multiple time steps look ahead training, we want to gradually in increase the horizon\n",
    "first need to figure out how to make the model to take in dynamic sequence length if it's not by default already"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "tf.reset_default_graph()\n",
    "\n",
    "batch_size = 32\n",
    "state_size = 100\n",
    "\n",
    "# cell\n",
    "lstm_cell = tf.nn.rnn_cell.BasicLSTMCell(state_size, forget_bias=1.)\n",
    "# initial state\n",
    "initial_state = lstm_cell.zero_state(batch_size, dtype=tf.float32)\n",
    "\n",
    "# input \n",
    "h = tf.placeholder(tf.int32)\n",
    "X = tf.placeholder(tf.float32, [batch_size, None, 1], name = 'train_input')\n",
    "Y = tf.placeholder(tf.float32, [batch_size, None, 1], name = 'train_label')\n",
    "\n",
    "output, last_states = sampling_rnn(cell=lstm_cell, \n",
    "                                   initial_state=initial_state, \n",
    "                                   input_=X,\n",
    "                                   batch_size=batch_size,\n",
    "                                   seq_lengths=h)\n",
    "# output as the prediction\n",
    "# pred = tf.reshape(output, (batch_size, seq_len, 1))\n",
    "\n",
    "print(output.shape)\n",
    "pred = output\n",
    "# pred = tf.reshape(output, (batch_size, h, 1))\n",
    "# pred = tf.reshape(output, (batch_size, h, 1))\n",
    "\n",
    "print('label shape:{0:} | output prediction shape: {1:}'.format(Y.shape, pred.shape))\n",
    "# loss\n",
    "loss = tf.losses.mean_squared_error(Y, pred)\n",
    "# optimzier\n",
    "opt = tf.train.AdamOptimizer().minimize(loss)\n",
    "\n",
    "# session\n",
    "sess = tf.Session()\n",
    "# Initializing the variables\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# iterate\n",
    "printn = 1e2\n",
    "horizon = 5\n",
    "for k in range(1, horizon+1):\n",
    "    print('Horizon {} ======'.format(k+1))\n",
    "    # chunk it to each small window\n",
    "    seq_len = k + 1\n",
    "    train_x = copy.deepcopy(get_sequences(train_original_x, seq_len, 1))\n",
    "    for i in range(1000):\n",
    "        epoch_loss =0.\n",
    "        for batch in iterate_minibatches(train_x, np.roll(train_x, -1), batch_size, shuffle=False):\n",
    "            train_xi, train_yi = batch\n",
    "            print(train_xi.shape, train_yi.shape)\n",
    "            p, l, _ = sess.run([output, loss, opt], feed_dict={X: train_xi, Y: train_yi, h:seq_len})\n",
    "            epoch_loss += l\n",
    "\n",
    "        if i%printn ==0:\n",
    "            print('Epoch {0:} | loss: {1:.4f}'.format(i, epoch_loss))\n",
    "    \n",
    "    \n",
    "# # save model\n",
    "# #Create a saver object which will save all the variables\n",
    "# saver = tf.train.Saver()\n",
    "# #save the graph\n",
    "# saver.save(sess, save_path='./models/test_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make test set\n",
    "test_x = get_sequences(test_x, seq_len, 1)\n",
    "# randomly choose some test segment\n",
    "# test_ind = np.random.randint(0, test_x.shape[0]-batch_size-1)\n",
    "test_ind = 0\n",
    "assert test_ind < test_x.shape[0]-batch_size-1, print('index is out of test set range with length ', len(test_x), test_x.shape[0]-batch_size-1)\n",
    "ctest_x = test_x[test_ind:test_ind+batch_size, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make plot test set\n",
    "plot_test_x = get_sequences(plot_test_x, seq_len, 1)\n",
    "plot_ctest_x = plot_test_x[test_ind:test_ind+batch_size, :, :]\n",
    "plot_ctest_x = plot_ctest_x.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test_x, test_y = get_minibatches(test_x, np.roll(test_x, -1), 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_pred = sess.run([output], feed_dict={X: ctest_x, h:seq_len})[0]\n",
    "test_pred = test_pred.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,8))\n",
    "plt.plot(plot_ctest_x, test_pred, plot_ctest_x, np.roll(ctest_x.reshape(-1), -1))\n",
    "plt.legend(['prediction', 'true label', 'smoothed'])\n",
    "plt.grid(True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
