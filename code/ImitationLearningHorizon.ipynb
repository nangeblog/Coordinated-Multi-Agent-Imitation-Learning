{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.ops.rnn import _transpose_batch_time\n",
    "from model import sampling_rnn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "from helpers import get_sequences, iterate_minibatches, get_minibatches, check_game_roles_duplicates\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import os\n",
    "# os.environ[\"TF_CPP_MIN_LOG_LEVEL\"]=\"3\"\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from utilities import LoadData\n",
    "from helpers import id_player, id_position, id_teams, get_player_trajectory, segment\n",
    "from model import rnn_horizon\n",
    "# ---------------------------------------------------------\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# directories\n",
    "main_dir = '../'\n",
    "game_dir = main_dir+'data/'\n",
    "Data = LoadData(main_dir, game_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we will use this fixed order as the role order\n",
    "roles = ['F', 'G', 'C-F', 'G-F', 'F-G', 'C', 'F-C']\n",
    "role_order = {'F': 0, 'G':4, 'C-F':1, 'G-F':3, 'F-G':3, 'C':2, 'F-C':1}\n",
    "# its possible that F has similar role as G-f or F-G, we create empty slots to ensure meta order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "game_id = '0021500463'\n",
    "game_data = Data.load_game(game_id)\n",
    "events = pd.DataFrame(game_data['events'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's just see the forward role model first, and ignore defending vs offending, use home vs visitor\n",
    "### also ignore sequence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_role = id_position(events)\n",
    "check_game_roles_duplicates(id_role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "homeid = events.loc[0].home['teamid']\n",
    "awayid = events.loc[0].visitor['teamid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events.loc[0].home['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_data['gamedate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(events.loc[0,'moments'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events['moments'].apply(lambda x: len(x)).values.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def order_moment(m, rm, ro, extreme=3):\n",
    "    '''\n",
    "        m: moments, rm: role model, ro: role order\n",
    "        for the case of multiple players sharing the smae roles,\n",
    "        (this can happen to even with hiddlen structure learning, \n",
    "         although it might be allevaited by using lienar assignment)\n",
    "        so for now, we come up with an extrem case where same role are occupied by say, 3 players,\n",
    "        then we still follow the meta order but create paddings 3 times.\n",
    "    '''\n",
    "    # reorder moments by role based mapping, where first col is player id\n",
    "    role = [rm[int(i)][0] for i in m[:,0]]\n",
    "    u_role = list(set(role))\n",
    "    assert len(u_role) >= 2, 'it goes over extreme case'\n",
    "    \n",
    "    d1,d2 = m.shape\n",
    "    try:\n",
    "        assert d1 == 5, 'd1,d2 = {0:}, {1:}'.format(d1, d2)\n",
    "    except:\n",
    "        print('Warning:', d1, d2, end='\\r')\n",
    "    # initialize slots (5 meta positions)\n",
    "    slots = np.zeros((extreme*5, d2))\n",
    "    counter = {}\n",
    "    for i in range(len(role)):\n",
    "        role_i = role[i]\n",
    "        if role_i not in counter.keys():\n",
    "            counter[role_i] = 0\n",
    "        else:\n",
    "            # note: this could possibly be better if add linear assignment\n",
    "            counter[role_i] += 1\n",
    "        # filling in the slots\n",
    "        slots[ro[role_i]*extreme+counter[role_i], :] = m[i, :]\n",
    "#     return slots[:, 1:] # [, 1:] slice 1 since we don't need the player id anymore\n",
    "    return slots[:, 1:] \n",
    "\n",
    "def one_hot_order(cat=None):\n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "    main_dir = '../'\n",
    "    game_dir = main_dir+'data/'\n",
    "    Data = LoadData(main_dir, game_dir)\n",
    "    cat = Data.load_csv('./meta_data/id_team.csv')\n",
    "    # binary encode\n",
    "    # ensure uniqueness\n",
    "    assert sum(cat.team_id.duplicated()) == 0\n",
    "    return dict(zip(cat.team_id, range(0, len(cat))))\n",
    "\n",
    "def one_hot_encode(mapping, teams):\n",
    "    nb_classes = len(mapping)\n",
    "    targets = np.array([mapping[int(i)] for i in teams])\n",
    "    one_hot_targets = np.eye(nb_classes)[targets]\n",
    "    \n",
    "    return one_hot_targets\n",
    "    \n",
    "def process_moments(moments, homeid, awayid):\n",
    "    result = []\n",
    "    for i in range(len(moments)):\n",
    "        # ball position array\n",
    "        dm = len(moments[i][5])\n",
    "        ball_ind = -1\n",
    "        player_ind = -1\n",
    "        if dm == 11: # ball is present\n",
    "            ball = np.array([moments[i][5][0][2:]])\n",
    "            player_ind = 1\n",
    "        elif dm == 10 and moments[i][5][0][:2] != [-1,-1]: # ball is not present\n",
    "            ball = np.array([[-1, -1, -1]])\n",
    "            player_ind = 0\n",
    "        else:\n",
    "            print('Warning!: There are less than 10 players! (skip)')\n",
    "            continue\n",
    "        # get player position data\n",
    "        pp = np.array(moments[i][5][player_ind:])\n",
    "        # home\n",
    "        hpp = pp[pp[:, 0]==homeid, :]\n",
    "        # visitor\n",
    "        vpp = pp[pp[:, 0]==awayid, :]\n",
    "           # add one hot encoding for the teams\n",
    "        h_team = hpp[:, 0]\n",
    "        v_team = vpp[:, 0]\n",
    "\n",
    "        hpp = np.column_stack((hpp[:, 1:], one_hot_encode(one_hot_order(), h_team)))\n",
    "        vpp = np.column_stack((vpp[:, 1:], one_hot_encode(one_hot_order(), v_team)))\n",
    "        \n",
    "        # reorder\n",
    "        # [:,:-1] ignores the team_id and the last null element\n",
    "        h = order_moment(hpp[:, :-1], id_role, role_order)\n",
    "        v = order_moment(vpp[:, :-1], id_role, role_order)\n",
    "\n",
    "        # combine home and visit\n",
    "        hv = np.vstack((h,v))\n",
    "        # stack on the ball position\n",
    "        result.append(np.column_stack((hv, np.repeat(ball, hv.shape[0],0))))\n",
    "    result = np.array(result) \n",
    "    return result.reshape(result.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# a = events.loc[0,'moments']\n",
    "# # print(len(a), len(a)*10*2*5)\n",
    "# e0 = process_moments(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events.loc[221, :].home['teamid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events.moments[221][29]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# e0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "homeid = events.loc[0].home['teamid']\n",
    "awayid = events.loc[0].visitor['teamid']\n",
    "single_game = []\n",
    "len_th = 10\n",
    "n = 0\n",
    "n_short = 0\n",
    "for k, v in enumerate(events.moments.values):\n",
    "    print('>>>>>>>', k, end='\\r')\n",
    "    pm = process_moments(v,homeid, awayid)\n",
    "    if pm.shape[0] >= len_th:\n",
    "        single_game.append(pm)\n",
    "        n += 1\n",
    "    else:\n",
    "        n_short += 1\n",
    "print(n, n_short)\n",
    "# dimensions extreme<3> x n_players<10> x (player_pos<2> + teamid_onehot<25> + ball<3>) = 900"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_game[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# a,b = get_minibatches(signle_game[0], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lets first predict role F (ignored the extreme)\n",
    "game_target = [np.roll(i[:, :2], -1, axis=0) for i in single_game]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 900\n",
    "single_game[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_target[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# single_game[0]\n",
    "seq_len = 10\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # train x\n",
    "# train_x = [get_sequences(i, seq_len, D) for i in single_game]\n",
    "# train_x = np.concatenate(train_x, axis=0)\n",
    "# # train y\n",
    "# train_y = [get_sequences(i, seq_len, 2) for i in game_target]\n",
    "# train_y = np.concatenate(train_y, axis=0)\n",
    "\n",
    "# train_x_batches, train_y_batches = get_minibatches(train_x, train_y, batch_size) \n",
    "# train_x_batches.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_x_batches.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_y_batches.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# batch_size = 32\n",
    "state_size = 512\n",
    "\n",
    "# cell\n",
    "lstm_cell = tf.nn.rnn_cell.BasicLSTMCell(state_size, forget_bias=1.)\n",
    "# initial state\n",
    "initial_state = lstm_cell.zero_state(batch_size, dtype=tf.float32)\n",
    "\n",
    "# input \n",
    "h = tf.placeholder(tf.int32)\n",
    "X = tf.placeholder(tf.float32, [batch_size, None, D], name = 'train_input')\n",
    "Y = tf.placeholder(tf.float32, [batch_size, None, 2], name = 'train_label')\n",
    "print('=================0')\n",
    "output, last_states = rnn_horizon(cell=lstm_cell, \n",
    "                                  initial_state=initial_state, \n",
    "                                  input_=X,\n",
    "                                  batch_size=batch_size,\n",
    "                                  seq_lengths=h)\n",
    "# output as the prediction\n",
    "# pred = tf.reshape(output, (batch_size, seq_len, 1))\n",
    "\n",
    "print('output shape, last_states', output.shape)#, last_states.shape)\n",
    "print('=================1')\n",
    "pred = output\n",
    "# pred = tf.reshape(output, (batch_size, h, 1))\n",
    "# pred = tf.reshape(output, (batch_size, h, 1))\n",
    "\n",
    "print('=================label shape:{0:} | output prediction shape: {1:}'.format(Y.shape, pred.shape))\n",
    "# loss\n",
    "loss = tf.losses.mean_squared_error(Y, pred)\n",
    "print('=================2')\n",
    "# optimzier\n",
    "opt = tf.train.AdamOptimizer().minimize(loss)\n",
    "print('=================3')\n",
    "# session\n",
    "sess = tf.Session()\n",
    "print('=================4')\n",
    "# Initializing the variables\n",
    "sess.run(tf.global_variables_initializer())\n",
    "print('=================5')\n",
    "# iterate\n",
    "printn = 1e2\n",
    "horizon = 5\n",
    "for k in range(1, horizon+1):\n",
    "    print('Horizon {} ======'.format(k+1))\n",
    "    # chunk it to each small window\n",
    "#     seq_len = k + 1\n",
    "    seq_len = 5\n",
    "#     seq_len = 8\n",
    "#     train_x = copy.deepcopy(get_sequences(train_original_x, seq_len, 1))\n",
    "\n",
    "    # train x\n",
    "    train_x = copy.deepcopy([get_sequences(i, seq_len, D) for i in single_game])\n",
    "    train_x = copy.deepcopy(np.concatenate(train_x, axis=0))\n",
    "    print('train_x.shape:', train_x.shape)\n",
    "    # train y\n",
    "    train_y = copy.deepcopy([get_sequences(i, seq_len, 2) for i in game_target])\n",
    "    train_y = copy.deepcopy(np.concatenate(train_y, axis=0))\n",
    "    print('train_y.shape:', train_y.shape)\n",
    "    for i in range(1000):\n",
    "        epoch_loss =0.\n",
    "        for batch in iterate_minibatches(train_x, train_y, batch_size, shuffle=False):\n",
    "            train_xi, train_yi = batch\n",
    "            print('in iterate bach train_xi.shape, train_yi.shape', train_xi.shape, train_yi.shape)\n",
    "            p, l, _ = sess.run([output, loss, opt], feed_dict={X: train_xi, Y: train_yi, h:seq_len})\n",
    "            epoch_loss += l\n",
    "\n",
    "        if i%printn ==0:\n",
    "            print('Epoch {0:} | loss: {1:.5f}'.format(i, epoch_loss))\n",
    "    \n",
    "    \n",
    "# # save model\n",
    "# #Create a saver object which will save all the variables\n",
    "# saver = tf.train.Saver()\n",
    "# #save the graph\n",
    "# saver.save(sess, save_path='./models/test_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
