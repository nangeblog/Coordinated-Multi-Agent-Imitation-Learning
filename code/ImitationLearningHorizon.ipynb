{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sam/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.ops.rnn import _transpose_batch_time\n",
    "from model import sampling_rnn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "from helpers import get_sequences, iterate_minibatches, get_minibatches, check_game_roles_duplicates\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import os\n",
    "# os.environ[\"TF_CPP_MIN_LOG_LEVEL\"]=\"3\"\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from utilities import LoadData\n",
    "from helpers import id_player, id_position, id_teams, get_player_trajectory, segment\n",
    "from model import rnn_horizon\n",
    "# ---------------------------------------------------------\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# directories\n",
    "main_dir = '../'\n",
    "game_dir = main_dir+'data/'\n",
    "Data = LoadData(main_dir, game_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we will use this fixed order as the role order\n",
    "roles = ['F', 'G', 'C-F', 'G-F', 'F-G', 'C', 'F-C']\n",
    "role_order = {'F': 0, 'G':4, 'C-F':1, 'G-F':3, 'F-G':3, 'C':2, 'F-C':1}\n",
    "# its possible that F has similar role as G-f or F-G, we create empty slots to ensure meta order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.1 s, sys: 196 ms, total: 11.3 s\n",
      "Wall time: 11.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "game_id = '0021500463'\n",
    "game_data = Data.load_game(game_id)\n",
    "events = pd.DataFrame(game_data['events'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's just see the forward role model first, and ignore defending vs offending, use home vs visitor\n",
    "### also ignore sequence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_role = id_position(events)\n",
    "check_game_roles_duplicates(id_role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "homeid = events.loc[0].home['teamid']\n",
    "awayid = events.loc[0].visitor['teamid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Chicago Bulls'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events.loc[0].home['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2015-12-28'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game_data['gamedate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(events.loc[0,'moments'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events['moments'].apply(lambda x: len(x)).values.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def order_moment(m, rm, ro, extreme=3):\n",
    "    '''\n",
    "        m: moments, rm: role model, ro: role order\n",
    "        for the case of multiple players sharing the smae roles,\n",
    "        (this can happen to even with hiddlen structure learning, \n",
    "         although it might be allevaited by using lienar assignment)\n",
    "        so for now, we come up with an extrem case where same role are occupied by say, 3 players,\n",
    "        then we still follow the meta order but create paddings 3 times.\n",
    "    '''\n",
    "    # reorder moments by role based mapping, where first col is player id\n",
    "    role = [rm[int(i)][0] for i in m[:,0]]\n",
    "    u_role = list(set(role))\n",
    "    assert len(u_role) >= 2, 'it goes over extreme case'\n",
    "    \n",
    "    d1,d2 = m.shape\n",
    "    try:\n",
    "        assert d1 == 5, 'd1,d2 = {0:}, {1:}'.format(d1, d2)\n",
    "    except:\n",
    "        print('Warning:', d1, d2, end='\\r')\n",
    "    # initialize slots (5 meta positions)\n",
    "    slots = np.zeros((extreme*5, d2))\n",
    "    counter = {}\n",
    "    for i in range(len(role)):\n",
    "        role_i = role[i]\n",
    "        if role_i not in counter.keys():\n",
    "            counter[role_i] = 0\n",
    "        else:\n",
    "            # note: this could possibly be better if add linear assignment\n",
    "            counter[role_i] += 1\n",
    "        # filling in the slots\n",
    "        slots[ro[role_i]*extreme+counter[role_i], :] = m[i, :]\n",
    "#     return slots[:, 1:] # [, 1:] slice 1 since we don't need the player id anymore\n",
    "    return slots[:, 1:] \n",
    "\n",
    "def one_hot_order(cat=None):\n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "    main_dir = '../'\n",
    "    game_dir = main_dir+'data/'\n",
    "    Data = LoadData(main_dir, game_dir)\n",
    "    cat = Data.load_csv('./meta_data/id_team.csv')\n",
    "    # binary encode\n",
    "    # ensure uniqueness\n",
    "    assert sum(cat.team_id.duplicated()) == 0\n",
    "    return dict(zip(cat.team_id, range(0, len(cat))))\n",
    "\n",
    "def one_hot_encode(mapping, teams):\n",
    "    nb_classes = len(mapping)\n",
    "    targets = np.array([mapping[int(i)] for i in teams])\n",
    "    one_hot_targets = np.eye(nb_classes)[targets]\n",
    "    \n",
    "    return one_hot_targets\n",
    "    \n",
    "def process_moments(moments, homeid, awayid):\n",
    "    result = []\n",
    "    for i in range(len(moments)):\n",
    "        # ball position array\n",
    "        dm = len(moments[i][5])\n",
    "        ball_ind = -1\n",
    "        player_ind = -1\n",
    "        if dm == 11: # ball is present\n",
    "            ball = np.array([moments[i][5][0][2:]])\n",
    "            player_ind = 1\n",
    "        elif dm == 10 and moments[i][5][0][:2] != [-1,-1]: # ball is not present\n",
    "            ball = np.array([[-1, -1, -1]])\n",
    "            player_ind = 0\n",
    "        else:\n",
    "            print('Warning!: There are less than 10 players! (skip)')\n",
    "            continue\n",
    "        # get player position data\n",
    "        pp = np.array(moments[i][5][player_ind:])\n",
    "        # home\n",
    "        hpp = pp[pp[:, 0]==homeid, :]\n",
    "        # visitor\n",
    "        vpp = pp[pp[:, 0]==awayid, :]\n",
    "           # add one hot encoding for the teams\n",
    "        h_team = hpp[:, 0]\n",
    "        v_team = vpp[:, 0]\n",
    "\n",
    "        hpp = np.column_stack((hpp[:, 1:], one_hot_encode(one_hot_order(), h_team)))\n",
    "        vpp = np.column_stack((vpp[:, 1:], one_hot_encode(one_hot_order(), v_team)))\n",
    "        \n",
    "        # reorder\n",
    "        # [:,:-1] ignores the team_id and the last null element\n",
    "        h = order_moment(hpp[:, :-1], id_role, role_order)\n",
    "        v = order_moment(vpp[:, :-1], id_role, role_order)\n",
    "\n",
    "        # combine home and visit\n",
    "        hv = np.vstack((h,v))\n",
    "        # stack on the ball position\n",
    "        result.append(np.column_stack((hv, np.repeat(ball, hv.shape[0],0))))\n",
    "    result = np.array(result) \n",
    "    return result.reshape(result.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# a = events.loc[0,'moments']\n",
    "# # print(len(a), len(a)*10*2*5)\n",
    "# e0 = process_moments(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1610612741"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events.loc[221, :].home['teamid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4,\n",
       " 1451358777223,\n",
       " 63.0,\n",
       " None,\n",
       " None,\n",
       " [[-1, -1, 75.46226, 24.81421, 2.9923],\n",
       "  [1610612741, 2200, 85.16542, 14.22962, 0.0],\n",
       "  [1610612741, 201166, 66.30584, 17.15957, 0.0],\n",
       "  [1610612741, 202710, 87.15369, 33.42979, 0.0],\n",
       "  [1610612741, 203503, 82.85255, 33.22433, 0.0],\n",
       "  [1610612761, 201960, 84.78216, 33.17034, 0.0],\n",
       "  [1610612761, 200768, 74.49802, 25.36242, 0.0],\n",
       "  [1610612761, 201942, 57.10716, 29.50134, 0.0],\n",
       "  [1610612761, 203082, 64.77583, 19.00113, 0.0]]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events.moments[221][29]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(231, 8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# e0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning!: There are less than 10 players! (skip)\n",
      "Warning!: There are less than 10 players! (skip)\n",
      "Warning!: There are less than 10 players! (skip)\n",
      "230 1>> 230\n",
      "CPU times: user 2min 34s, sys: 1.51 s, total: 2min 35s\n",
      "Wall time: 2min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "homeid = events.loc[0].home['teamid']\n",
    "awayid = events.loc[0].visitor['teamid']\n",
    "single_game = []\n",
    "len_th = 10\n",
    "n = 0\n",
    "n_short = 0\n",
    "for k, v in enumerate(events.moments.values):\n",
    "    print('>>>>>>>', k, end='\\r')\n",
    "    pm = process_moments(v,homeid, awayid)\n",
    "    if pm.shape[0] >= len_th:\n",
    "        single_game.append(pm)\n",
    "        n += 1\n",
    "    else:\n",
    "        n_short += 1\n",
    "print(n, n_short)\n",
    "# dimensions extreme<3> x n_players<10> x (player_pos<2> + teamid_onehot<25> + ball<3>) = 900"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16.79035, 20.55978,  0.     , ..., 18.38063, 14.07976,  8.56325],\n",
       "       [16.47709, 20.40799,  0.     , ..., 18.29249, 14.14733,  8.97331],\n",
       "       [16.21462, 20.19832,  0.     , ..., 18.17901, 14.27343,  9.20931],\n",
       "       ...,\n",
       "       [57.65112, 14.11472,  0.     , ..., 36.21928, 41.42113,  5.03485],\n",
       "       [58.00482, 14.12736,  0.     , ..., 36.61226, 41.57427,  5.1757 ],\n",
       "       [58.36874, 14.13119,  0.     , ..., 36.94039, 41.79393,  5.37554]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_game[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# a,b = get_minibatches(signle_game[0], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lets first predict role F (ignored the extreme)\n",
    "game_target = [np.roll(i[:, :2], -1, axis=0) for i in single_game]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 900)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D = 900\n",
    "single_game[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 2)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game_target[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# single_game[0]\n",
    "seq_len = 10\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # train x\n",
    "# train_x = [get_sequences(i, seq_len, D) for i in single_game]\n",
    "# train_x = np.concatenate(train_x, axis=0)\n",
    "# # train y\n",
    "# train_y = [get_sequences(i, seq_len, 2) for i in game_target]\n",
    "# train_y = np.concatenate(train_y, axis=0)\n",
    "\n",
    "# train_x_batches, train_y_batches = get_minibatches(train_x, train_y, batch_size) \n",
    "# train_x_batches.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_x_batches.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_y_batches.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>> Tensor(\"Placeholder:0\", dtype=int32) <<<<<<<<<<<<<<\n",
      "finished value: Tensor(\"rnn/All:0\", shape=(), dtype=bool) =====================\n",
      "\n",
      "finished value: Tensor(\"rnn/while/All_1:0\", shape=(), dtype=bool) =====================\n",
      "\n",
      "output shape (32, ?, 2)\n",
      "label shape:(32, ?, 2) | output prediction shape: (32, ?, 2)\n",
      "Horizon 2 ======\n",
      "(32, 2, 900) (32, 2, 2)\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Tried to read from index 2 but array size is: 2\n\t [[Node: rnn/while/TensorArrayReadV3 = TensorArrayReadV3[dtype=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](rnn/while/TensorArrayReadV3/Enter, rnn/while/add, rnn/while/TensorArrayReadV3/Enter_1)]]\n\nCaused by op 'rnn/while/TensorArrayReadV3', defined at:\n  File \"/home/sam/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/sam/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/sam/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/sam/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/sam/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/sam/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/sam/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/sam/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/sam/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/sam/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/sam/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/sam/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/sam/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/sam/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/sam/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/sam/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/sam/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/sam/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/sam/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2827, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/sam/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-48-fcc02342d898>\", line 1, in <module>\n    get_ipython().run_cell_magic('time', '', \"tf.reset_default_graph()\\n\\n# batch_size = 32\\nstate_size = 100\\n\\n# cell\\nlstm_cell = tf.nn.rnn_cell.BasicLSTMCell(state_size, forget_bias=1.)\\n# initial state\\ninitial_state = lstm_cell.zero_state(batch_size, dtype=tf.float32)\\n\\n# input \\nh = tf.placeholder(tf.int32)\\nX = tf.placeholder(tf.float32, [batch_size, None, D], name = 'train_input')\\nY = tf.placeholder(tf.float32, [batch_size, None, 2], name = 'train_label')\\n\\noutput, last_states = rnn_horizon(cell=lstm_cell, \\n                                   initial_state=initial_state, \\n                                   input_=X,\\n                                   batch_size=batch_size,\\n                                   seq_lengths=h)\\n# output as the prediction\\n# pred = tf.reshape(output, (batch_size, seq_len, 1))\\n\\nprint('output shape', output.shape)\\npred = output\\n# pred = tf.reshape(output, (batch_size, h, 1))\\n# pred = tf.reshape(output, (batch_size, h, 1))\\n\\nprint('label shape:{0:} | output prediction shape: {1:}'.format(Y.shape, pred.shape))\\n# loss\\nloss = tf.losses.mean_squared_error(Y, pred)\\n# optimzier\\nopt = tf.train.AdamOptimizer().minimize(loss)\\n\\n# session\\nsess = tf.Session()\\n# Initializing the variables\\nsess.run(tf.global_variables_initializer())\\n\\n# iterate\\nprintn = 1e2\\nhorizon = 5\\nfor k in range(1, horizon+1):\\n    print('Horizon {} ======'.format(k+1))\\n    # chunk it to each small window\\n    seq_len = k + 1\\n#     seq_len = 8\\n#     train_x = copy.deepcopy(get_sequences(train_original_x, seq_len, 1))\\n\\n    # train x\\n    train_x = copy.deepcopy([get_sequences(i, seq_len, D) for i in single_game])\\n    train_x = copy.deepcopy(np.concatenate(train_x, axis=0))\\n    # train y\\n    train_y = copy.deepcopy([get_sequences(i, seq_len, 2) for i in game_target])\\n    train_y = copy.deepcopy(np.concatenate(train_y, axis=0))\\n    for i in range(1000):\\n        epoch_loss =0.\\n        for batch in iterate_minibatches(train_x, train_y, batch_size, shuffle=False):\\n            train_xi, train_yi = batch\\n            print(train_xi.shape, train_yi.shape)\\n            p, l, _ = sess.run([output, loss, opt], feed_dict={X: train_xi, Y: train_yi, h:seq_len})\\n            epoch_loss += l\\n\\n        if i%printn ==0:\\n            print('Epoch {0:} | loss: {1:.5f}'.format(i, epoch_loss))\\n    \\n    \\n# # save model\\n# #Create a saver object which will save all the variables\\n# saver = tf.train.Saver()\\n# #save the graph\\n# saver.save(sess, save_path='./models/test_model')\")\n  File \"/home/sam/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2115, in run_cell_magic\n    result = fn(magic_arg_s, cell)\n  File \"<decorator-gen-59>\", line 2, in time\n  File \"/home/sam/anaconda3/lib/python3.6/site-packages/IPython/core/magic.py\", line 188, in <lambda>\n    call = lambda f, *a, **k: f(*a, **k)\n  File \"/home/sam/anaconda3/lib/python3.6/site-packages/IPython/core/magics/execution.py\", line 1185, in time\n    exec(code, glob, local_ns)\n  File \"<timed exec>\", line 20, in <module>\n  File \"/home/sam/Desktop/raptors/code/model.py\", line 148, in rnn_horizon\n    outputs_ta, last_state, _ = tf.nn.raw_rnn(cell, loop_fn)\n  File \"/home/sam/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py\", line 1157, in raw_rnn\n    swap_memory=swap_memory)\n  File \"/home/sam/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 3202, in while_loop\n    result = loop_context.BuildLoop(cond, body, loop_vars, shape_invariants)\n  File \"/home/sam/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2940, in BuildLoop\n    pred, body, original_loop_vars, loop_vars, shape_invariants)\n  File \"/home/sam/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2877, in _BuildLoop\n    body_result = body(*packed_vars_for_body)\n  File \"/home/sam/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py\", line 1118, in body\n    next_time, next_output, cell_state, loop_state)\n  File \"/home/sam/Desktop/raptors/code/model.py\", line 126, in loop_fn\n    input_original = inputs_ta.read(time)  # tensor of shape (None, input_dim)\n  File \"/home/sam/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py\", line 58, in fn\n    return method(self, *args, **kwargs)\n  File \"/home/sam/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py\", line 58, in fn\n    return method(self, *args, **kwargs)\n  File \"/home/sam/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py\", line 58, in fn\n    return method(self, *args, **kwargs)\n  File \"/home/sam/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/tensor_array_ops.py\", line 861, in read\n    return self._implementation.read(index, name=name)\n  File \"/home/sam/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/tensor_array_ops.py\", line 260, in read\n    name=name)\n  File \"/home/sam/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_data_flow_ops.py\", line 6419, in tensor_array_read_v3\n    dtype=dtype, name=name)\n  File \"/home/sam/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/sam/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3290, in create_op\n    op_def=op_def)\n  File \"/home/sam/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1654, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Tried to read from index 2 but array size is: 2\n\t [[Node: rnn/while/TensorArrayReadV3 = TensorArrayReadV3[dtype=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](rnn/while/TensorArrayReadV3/Enter, rnn/while/add, rnn/while/TensorArrayReadV3/Enter_1)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/home/sam/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sam/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1312\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sam/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m             status, run_metadata)\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sam/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    517\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Tried to read from index 2 but array size is: 2\n\t [[Node: rnn/while/TensorArrayReadV3 = TensorArrayReadV3[dtype=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](rnn/while/TensorArrayReadV3/Enter, rnn/while/add, rnn/while/TensorArrayReadV3/Enter_1)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-fcc02342d898>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tf.reset_default_graph()\\n\\n# batch_size = 32\\nstate_size = 100\\n\\n# cell\\nlstm_cell = tf.nn.rnn_cell.BasicLSTMCell(state_size, forget_bias=1.)\\n# initial state\\ninitial_state = lstm_cell.zero_state(batch_size, dtype=tf.float32)\\n\\n# input \\nh = tf.placeholder(tf.int32)\\nX = tf.placeholder(tf.float32, [batch_size, None, D], name = 'train_input')\\nY = tf.placeholder(tf.float32, [batch_size, None, 2], name = 'train_label')\\n\\noutput, last_states = rnn_horizon(cell=lstm_cell, \\n                                   initial_state=initial_state, \\n                                   input_=X,\\n                                   batch_size=batch_size,\\n                                   seq_lengths=h)\\n# output as the prediction\\n# pred = tf.reshape(output, (batch_size, seq_len, 1))\\n\\nprint('output shape', output.shape)\\npred = output\\n# pred = tf.reshape(output, (batch_size, h, 1))\\n# pred = tf.reshape(output, (batch_size, h, 1))\\n\\nprint('label shape:{0:} | output prediction shape: {1:}'.format(Y.shape, pred.shape))\\n# loss\\nloss = tf.losses.mean_squared_error(Y, pred)\\n# optimzier\\nopt = tf.train.AdamOptimizer().minimize(loss)\\n\\n# session\\nsess = tf.Session()\\n# Initializing the variables\\nsess.run(tf.global_variables_initializer())\\n\\n# iterate\\nprintn = 1e2\\nhorizon = 5\\nfor k in range(1, horizon+1):\\n    print('Horizon {} ======'.format(k+1))\\n    # chunk it to each small window\\n    seq_len = k + 1\\n#     seq_len = 8\\n#     train_x = copy.deepcopy(get_sequences(train_original_x, seq_len, 1))\\n\\n    # train x\\n    train_x = copy.deepcopy([get_sequences(i, seq_len, D) for i in single_game])\\n    train_x = copy.deepcopy(np.concatenate(train_x, axis=0))\\n    # train y\\n    train_y = copy.deepcopy([get_sequences(i, seq_len, 2) for i in game_target])\\n    train_y = copy.deepcopy(np.concatenate(train_y, axis=0))\\n    for i in range(1000):\\n        epoch_loss =0.\\n        for batch in iterate_minibatches(train_x, train_y, batch_size, shuffle=False):\\n            train_xi, train_yi = batch\\n            print(train_xi.shape, train_yi.shape)\\n            p, l, _ = sess.run([output, loss, opt], feed_dict={X: train_xi, Y: train_yi, h:seq_len})\\n            epoch_loss += l\\n\\n        if i%printn ==0:\\n            print('Epoch {0:} | loss: {1:.5f}'.format(i, epoch_loss))\\n    \\n    \\n# # save model\\n# #Create a saver object which will save all the variables\\n# saver = tf.train.Saver()\\n# #save the graph\\n# saver.save(sess, save_path='./models/test_model')\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/sam/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2113\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2114\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2115\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2116\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-59>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m/home/sam/anaconda3/lib/python3.6/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sam/anaconda3/lib/python3.6/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1183\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1185\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1186\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/home/sam/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sam/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1140\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sam/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1321\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sam/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Tried to read from index 2 but array size is: 2\n\t [[Node: rnn/while/TensorArrayReadV3 = TensorArrayReadV3[dtype=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](rnn/while/TensorArrayReadV3/Enter, rnn/while/add, rnn/while/TensorArrayReadV3/Enter_1)]]\n\nCaused by op 'rnn/while/TensorArrayReadV3', defined at:\n  File \"/home/sam/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/sam/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/sam/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/sam/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/sam/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/sam/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/sam/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/sam/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/sam/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/sam/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/sam/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/sam/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/sam/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/sam/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/sam/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/sam/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/sam/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/sam/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/sam/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2827, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/sam/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-48-fcc02342d898>\", line 1, in <module>\n    get_ipython().run_cell_magic('time', '', \"tf.reset_default_graph()\\n\\n# batch_size = 32\\nstate_size = 100\\n\\n# cell\\nlstm_cell = tf.nn.rnn_cell.BasicLSTMCell(state_size, forget_bias=1.)\\n# initial state\\ninitial_state = lstm_cell.zero_state(batch_size, dtype=tf.float32)\\n\\n# input \\nh = tf.placeholder(tf.int32)\\nX = tf.placeholder(tf.float32, [batch_size, None, D], name = 'train_input')\\nY = tf.placeholder(tf.float32, [batch_size, None, 2], name = 'train_label')\\n\\noutput, last_states = rnn_horizon(cell=lstm_cell, \\n                                   initial_state=initial_state, \\n                                   input_=X,\\n                                   batch_size=batch_size,\\n                                   seq_lengths=h)\\n# output as the prediction\\n# pred = tf.reshape(output, (batch_size, seq_len, 1))\\n\\nprint('output shape', output.shape)\\npred = output\\n# pred = tf.reshape(output, (batch_size, h, 1))\\n# pred = tf.reshape(output, (batch_size, h, 1))\\n\\nprint('label shape:{0:} | output prediction shape: {1:}'.format(Y.shape, pred.shape))\\n# loss\\nloss = tf.losses.mean_squared_error(Y, pred)\\n# optimzier\\nopt = tf.train.AdamOptimizer().minimize(loss)\\n\\n# session\\nsess = tf.Session()\\n# Initializing the variables\\nsess.run(tf.global_variables_initializer())\\n\\n# iterate\\nprintn = 1e2\\nhorizon = 5\\nfor k in range(1, horizon+1):\\n    print('Horizon {} ======'.format(k+1))\\n    # chunk it to each small window\\n    seq_len = k + 1\\n#     seq_len = 8\\n#     train_x = copy.deepcopy(get_sequences(train_original_x, seq_len, 1))\\n\\n    # train x\\n    train_x = copy.deepcopy([get_sequences(i, seq_len, D) for i in single_game])\\n    train_x = copy.deepcopy(np.concatenate(train_x, axis=0))\\n    # train y\\n    train_y = copy.deepcopy([get_sequences(i, seq_len, 2) for i in game_target])\\n    train_y = copy.deepcopy(np.concatenate(train_y, axis=0))\\n    for i in range(1000):\\n        epoch_loss =0.\\n        for batch in iterate_minibatches(train_x, train_y, batch_size, shuffle=False):\\n            train_xi, train_yi = batch\\n            print(train_xi.shape, train_yi.shape)\\n            p, l, _ = sess.run([output, loss, opt], feed_dict={X: train_xi, Y: train_yi, h:seq_len})\\n            epoch_loss += l\\n\\n        if i%printn ==0:\\n            print('Epoch {0:} | loss: {1:.5f}'.format(i, epoch_loss))\\n    \\n    \\n# # save model\\n# #Create a saver object which will save all the variables\\n# saver = tf.train.Saver()\\n# #save the graph\\n# saver.save(sess, save_path='./models/test_model')\")\n  File \"/home/sam/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2115, in run_cell_magic\n    result = fn(magic_arg_s, cell)\n  File \"<decorator-gen-59>\", line 2, in time\n  File \"/home/sam/anaconda3/lib/python3.6/site-packages/IPython/core/magic.py\", line 188, in <lambda>\n    call = lambda f, *a, **k: f(*a, **k)\n  File \"/home/sam/anaconda3/lib/python3.6/site-packages/IPython/core/magics/execution.py\", line 1185, in time\n    exec(code, glob, local_ns)\n  File \"<timed exec>\", line 20, in <module>\n  File \"/home/sam/Desktop/raptors/code/model.py\", line 148, in rnn_horizon\n    outputs_ta, last_state, _ = tf.nn.raw_rnn(cell, loop_fn)\n  File \"/home/sam/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py\", line 1157, in raw_rnn\n    swap_memory=swap_memory)\n  File \"/home/sam/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 3202, in while_loop\n    result = loop_context.BuildLoop(cond, body, loop_vars, shape_invariants)\n  File \"/home/sam/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2940, in BuildLoop\n    pred, body, original_loop_vars, loop_vars, shape_invariants)\n  File \"/home/sam/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2877, in _BuildLoop\n    body_result = body(*packed_vars_for_body)\n  File \"/home/sam/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py\", line 1118, in body\n    next_time, next_output, cell_state, loop_state)\n  File \"/home/sam/Desktop/raptors/code/model.py\", line 126, in loop_fn\n    input_original = inputs_ta.read(time)  # tensor of shape (None, input_dim)\n  File \"/home/sam/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py\", line 58, in fn\n    return method(self, *args, **kwargs)\n  File \"/home/sam/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py\", line 58, in fn\n    return method(self, *args, **kwargs)\n  File \"/home/sam/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py\", line 58, in fn\n    return method(self, *args, **kwargs)\n  File \"/home/sam/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/tensor_array_ops.py\", line 861, in read\n    return self._implementation.read(index, name=name)\n  File \"/home/sam/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/tensor_array_ops.py\", line 260, in read\n    name=name)\n  File \"/home/sam/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_data_flow_ops.py\", line 6419, in tensor_array_read_v3\n    dtype=dtype, name=name)\n  File \"/home/sam/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/sam/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3290, in create_op\n    op_def=op_def)\n  File \"/home/sam/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1654, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Tried to read from index 2 but array size is: 2\n\t [[Node: rnn/while/TensorArrayReadV3 = TensorArrayReadV3[dtype=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](rnn/while/TensorArrayReadV3/Enter, rnn/while/add, rnn/while/TensorArrayReadV3/Enter_1)]]\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# batch_size = 32\n",
    "state_size = 100\n",
    "\n",
    "# cell\n",
    "lstm_cell = tf.nn.rnn_cell.BasicLSTMCell(state_size, forget_bias=1.)\n",
    "# initial state\n",
    "initial_state = lstm_cell.zero_state(batch_size, dtype=tf.float32)\n",
    "\n",
    "# input \n",
    "h = tf.placeholder(tf.int32)\n",
    "X = tf.placeholder(tf.float32, [batch_size, None, D], name = 'train_input')\n",
    "Y = tf.placeholder(tf.float32, [batch_size, None, 2], name = 'train_label')\n",
    "\n",
    "output, last_states = rnn_horizon(cell=lstm_cell, \n",
    "                                   initial_state=initial_state, \n",
    "                                   input_=X,\n",
    "                                   batch_size=batch_size,\n",
    "                                   seq_lengths=h)\n",
    "# output as the prediction\n",
    "# pred = tf.reshape(output, (batch_size, seq_len, 1))\n",
    "\n",
    "print('output shape', output.shape)\n",
    "pred = output\n",
    "# pred = tf.reshape(output, (batch_size, h, 1))\n",
    "# pred = tf.reshape(output, (batch_size, h, 1))\n",
    "\n",
    "print('label shape:{0:} | output prediction shape: {1:}'.format(Y.shape, pred.shape))\n",
    "# loss\n",
    "loss = tf.losses.mean_squared_error(Y, pred)\n",
    "# optimzier\n",
    "opt = tf.train.AdamOptimizer().minimize(loss)\n",
    "\n",
    "# session\n",
    "sess = tf.Session()\n",
    "# Initializing the variables\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# iterate\n",
    "printn = 1e2\n",
    "horizon = 5\n",
    "for k in range(1, horizon+1):\n",
    "    print('Horizon {} ======'.format(k+1))\n",
    "    # chunk it to each small window\n",
    "    seq_len = k + 1\n",
    "#     seq_len = 8\n",
    "#     train_x = copy.deepcopy(get_sequences(train_original_x, seq_len, 1))\n",
    "\n",
    "    # train x\n",
    "    train_x = copy.deepcopy([get_sequences(i, seq_len, D) for i in single_game])\n",
    "    train_x = copy.deepcopy(np.concatenate(train_x, axis=0))\n",
    "    # train y\n",
    "    train_y = copy.deepcopy([get_sequences(i, seq_len, 2) for i in game_target])\n",
    "    train_y = copy.deepcopy(np.concatenate(train_y, axis=0))\n",
    "    for i in range(1000):\n",
    "        epoch_loss =0.\n",
    "        for batch in iterate_minibatches(train_x, train_y, batch_size, shuffle=False):\n",
    "            train_xi, train_yi = batch\n",
    "            print(train_xi.shape, train_yi.shape)\n",
    "            p, l, _ = sess.run([output, loss, opt], feed_dict={X: train_xi, Y: train_yi, h:seq_len})\n",
    "            epoch_loss += l\n",
    "\n",
    "        if i%printn ==0:\n",
    "            print('Epoch {0:} | loss: {1:.5f}'.format(i, epoch_loss))\n",
    "    \n",
    "    \n",
    "# # save model\n",
    "# #Create a saver object which will save all the variables\n",
    "# saver = tf.train.Saver()\n",
    "# #save the graph\n",
    "# saver.save(sess, save_path='./models/test_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
