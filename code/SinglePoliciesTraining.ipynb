{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.ops.rnn import _transpose_batch_time\n",
    "\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob, os, sys, math, warnings, copy, time, glob\n",
    "import matplotlib.pyplot as plt\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"]=\"3\"\n",
    "\n",
    "# customized ftns \n",
    "from preprocessing import process_game_data\n",
    "from utilities import *\n",
    "from model import *\n",
    "from train import train_all_single_policies\n",
    "# ---------------------------------------------------------\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "warnings.filterwarnings('ignore')\n",
    "# warnings.filterwarnings(action='once')\n",
    "# ---------------------------------------------------------\n",
    "# directories\n",
    "main_dir = '../'\n",
    "game_dir = main_dir+'data/'\n",
    "Data = LoadData(main_dir, game_dir)\n",
    "models_path = './models/' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-process \n",
    "filter events, subsample frames, add velocity, reorder moments, re-arrange team order\n",
    "shot clock, filter out event with short moments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# all_games_id = [i.split('/')[-1].split('.')[0] for i in glob.glob('../data/*.pkl')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_games_id = ['0021500024']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "event_threshold = 50\n",
    "subsample_factor = 2\n",
    "# single_game = process_game_data(game_id, events_df, event_threshold, subsample_factor)\n",
    "\n",
    "single_game = process_game_data(Data, all_games_id, event_threshold, subsample_factor)\n",
    "\n",
    "print('Final number of events:', len(single_game))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show the plot, for the sake of comparison with processed moment later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "game_id = all_games_id[0]\n",
    "Plot = PlotGame(game_id, main_dir, game_dir)\n",
    "# for i in range(plotn): \n",
    "# Plot.load_moment2img(game_data, event_number=0, moment_number=0, return_img=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt_ind = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# manual plot check\n",
    "print(plt_ind)\n",
    "plot_check(single_game, plt_ind)\n",
    "plt_ind += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build graph and starts training for all single policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sequence_length = 25\n",
    "overlap = 10\n",
    "batch_size = 64\n",
    "train_all_single_policies(single_game, batch_size, sequence_length, overlap, models_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pad short sequence and chunk long sequence with overlaps\n",
    "policy = 0\n",
    "train, target = get_sequences(single_game, policy, sequence_length, overlap)\n",
    "# create train and test set\n",
    "p = 0.8 # train percentage\n",
    "divider = int(len(train)*p)\n",
    "train_game, test_game = np.copy(train[:divider]), np.copy(train[divider:])\n",
    "train_target, test_target = np.copy(target[:divider]), np.copy(target[divider:])\n",
    "Model = ImportGraph('policy0/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# manual plot check\n",
    "plot_check(train_game, n)\n",
    "n+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use while loop to make sure the \n",
    "train_batches = get_minibatches(train_game, train_target, batch_size, shuffle=False)\n",
    "\n",
    "check_ind = np.random.randint(0, len(train_game)//batch_size)\n",
    "print('rand checking index: {0:} out of {1:}'.format(check_ind, len(train_game)//batch_size))\n",
    "\n",
    "input_xi, output_yi = train_batches\n",
    "\n",
    "y_pred = Model.forward_pass(input_xi[check_ind], h=1)\n",
    "y_true = output_yi[check_ind]\n",
    "    \n",
    "y_pred = y_pred[0][0].reshape(-1,2)\n",
    "y_true = y_true[0].reshape(-1,2)\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "for k in range(0, len(y_pred)):\n",
    "    plt.plot(y_pred[:, 0][k], y_pred[:, 1][k], linestyle=\"None\", marker=\"o\", markersize=k, color='g')\n",
    "    plt.plot(y_true[:, 0][k], y_true[:, 1][k], linestyle=\"None\", marker=\"o\", markersize=k, color='b')\n",
    "\n",
    "plt.plot(y_pred[:, 0], y_pred[:, 1],'g', y_true[:,0], y_true[:,1], 'b')#, pred_train[:, 0], pred_train[:, 1])\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To do:\n",
    "\n",
    "    - 1) Regularize the lstm\n",
    "    - 2) Figure out why there are blanks in the testing\n",
    "    - 3) may consider to collect those left out from the process of creating batches\n",
    "    - 4) related to 3), seq_len = 3 may create null batches \n",
    "\n",
    "    - Split data to defending and offending, as the model for e.g. forward role in deffending and offending should be pretty different. Remove particular events, like free-throw etc.\n",
    "    \n",
    "    - We can use the shot clock as an indicator of when the offending and defending switches.\n",
    "    \n",
    "    - The cameras oprate at 25 frames per second, so in order to learn realistic motions, either we sample the 25 frames, or extend the horizon to 50 for example or even longer(this might be too computationally heavy and model would probably drift a lot).\n",
    "    \n",
    "    - At the moment if we don't have defending or offending sepearted, at least we need to break down the sequences from the 24 secs shot clock, since it usually stands for a change in game state. (note: shot clock sometimes is None)\n",
    "    \n",
    "    - Add tensorboard visualization. Add validation performance (maybe, it would take longer). \n",
    "      tensorboard --logdir=./train_logs\n",
    "      \n",
    "    - Start thinking about 1) joint training 2) Hidden structure 3) Smooth learning\n",
    "    - from each sample to next sample theres not much change, subsample them "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Questions\n",
    "\n",
    "    * After a team scored and they go back to get ready for defense, is the going back trajectory pretty much random?\n",
    "    * Do player swap roles during the play? e.g. a forward swapped to a guard, is the forward roles a lot different from gaurds these day? (i.e. can you differentaite a player plaing forward from guard from the game) If yes, then the hidden structure learning/sequencing is necessary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
