{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob, os, sys\n",
    "from hmmlearn import hmm\n",
    "osp = sys.platform\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "\n",
    "from utilities import *\n",
    "from helpers import *\n",
    "# ---------------------------------------------------------\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings(action='once')\n",
    "# ---------------------------------------------------------\n",
    "# directories\n",
    "main_dir = '../'\n",
    "game_dir = main_dir+'data/'\n",
    "Data = LoadData(main_dir, game_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw events shape: (231, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>end_time_left</th>\n",
       "      <th>home</th>\n",
       "      <th>moments</th>\n",
       "      <th>orig_events</th>\n",
       "      <th>playbyplay</th>\n",
       "      <th>quarter</th>\n",
       "      <th>start_time_left</th>\n",
       "      <th>visitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>702.31</td>\n",
       "      <td>{'abbreviation': 'CHI', 'players': [{'playerid...</td>\n",
       "      <td>[[1, 1451351428029, 708.28, 12.78, None, [[-1,...</td>\n",
       "      <td>[0]</td>\n",
       "      <td>GAME_ID  EVENTNUM  EVENTMSGTYPE  EVENTMS...</td>\n",
       "      <td>1</td>\n",
       "      <td>708.28</td>\n",
       "      <td>{'abbreviation': 'TOR', 'players': [{'playerid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>686.28</td>\n",
       "      <td>{'abbreviation': 'CHI', 'players': [{'playerid...</td>\n",
       "      <td>[[1, 1451351428029, 708.28, 12.78, None, [[-1,...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>GAME_ID  EVENTNUM  EVENTMSGTYPE  EVENTMS...</td>\n",
       "      <td>1</td>\n",
       "      <td>708.28</td>\n",
       "      <td>{'abbreviation': 'TOR', 'players': [{'playerid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>668.42</td>\n",
       "      <td>{'abbreviation': 'CHI', 'players': [{'playerid...</td>\n",
       "      <td>[[1, 1451351444029, 692.25, 12.21, None, [[-1,...</td>\n",
       "      <td>[2, 3]</td>\n",
       "      <td>GAME_ID  EVENTNUM  EVENTMSGTYPE  EVENTMS...</td>\n",
       "      <td>1</td>\n",
       "      <td>692.25</td>\n",
       "      <td>{'abbreviation': 'TOR', 'players': [{'playerid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   end_time_left                                               home  \\\n",
       "0         702.31  {'abbreviation': 'CHI', 'players': [{'playerid...   \n",
       "1         686.28  {'abbreviation': 'CHI', 'players': [{'playerid...   \n",
       "2         668.42  {'abbreviation': 'CHI', 'players': [{'playerid...   \n",
       "\n",
       "                                             moments orig_events  \\\n",
       "0  [[1, 1451351428029, 708.28, 12.78, None, [[-1,...         [0]   \n",
       "1  [[1, 1451351428029, 708.28, 12.78, None, [[-1,...         [1]   \n",
       "2  [[1, 1451351444029, 692.25, 12.21, None, [[-1,...      [2, 3]   \n",
       "\n",
       "                                          playbyplay  quarter  \\\n",
       "0        GAME_ID  EVENTNUM  EVENTMSGTYPE  EVENTMS...        1   \n",
       "1        GAME_ID  EVENTNUM  EVENTMSGTYPE  EVENTMS...        1   \n",
       "2        GAME_ID  EVENTNUM  EVENTMSGTYPE  EVENTMS...        1   \n",
       "\n",
       "   start_time_left                                            visitor  \n",
       "0           708.28  {'abbreviation': 'TOR', 'players': [{'playerid...  \n",
       "1           708.28  {'abbreviation': 'TOR', 'players': [{'playerid...  \n",
       "2           692.25  {'abbreviation': 'TOR', 'players': [{'playerid...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%time\n",
    "game_id = '0021500463'\n",
    "game_data = Data.load_game(game_id)\n",
    "events_df = pd.DataFrame(game_data['events'])\n",
    "print('raw events shape:', events_df.shape)\n",
    "events_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get events and number of events\n",
    "# events_df = pd.DataFrame(data['events'])\n",
    "# n_events = events_df.shape[0]\n",
    "# # get numebr of moments\n",
    "# moments = events_df.iloc[event_number,:]['moments']\n",
    "# n_moments = len(moments)\n",
    "\n",
    "# print(n_moments, event_df.shape)\n",
    "# event_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # get all the player_id and player_name mapping\n",
    "# player_id_mapping = id_player(event_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # get position mapping\n",
    "# # get all the player_id and player_name mapping\n",
    "# position_id_mapping = id_position(event_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set(np.concatenate(list(position_id_mapping.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# play id to play roles/positions\n",
    "id_role = id_position(events_df)\n",
    "check_game_roles_duplicates(id_role)\n",
    "\n",
    "# we will use this fixed order as the role order\n",
    "roles = ['F', 'G', 'C-F', 'G-F', 'F-G', 'C', 'F-C']\n",
    "role_order = {'F': 0, 'G':4, 'C-F':1, 'G-F':3, 'F-G':3, 'C':2, 'F-C':1}\n",
    "\n",
    "# its possible that F has similar role as G-f or F-G, we create empty slots to ensure meta order\n",
    "# ddentify defending and offending runs (this is included in process_moments)\n",
    "court_index = Data.load_csv('./meta_data/court_index.csv')\n",
    "court_index = dict(zip(court_index.game_id, court_index.court_position))\n",
    "\n",
    "# home and visitor ids\n",
    "homeid = events_df.loc[0].home['teamid']\n",
    "awayid = events_df.loc[0].visitor['teamid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning!: There are less than 10 players! (skip)\n",
      "Warning!: There are less than 10 players! (skip)\n",
      "Warning!: There are less than 10 players! (skip)\n"
     ]
    }
   ],
   "source": [
    "single_game = []\n",
    "for i in events_df.moments.values:\n",
    "    result_i = process_moments_ra(i, homeid, awayid, court_index, game_id)\n",
    "    if result_i == None:\n",
    "        continue\n",
    "    else:\n",
    "        pm, scs = result_i\n",
    "        d1,d2,d3 = pm.shape\n",
    "        single_game.append(pm.reshape(d1, d2*d3))\n",
    "        \n",
    "seq_lens = np.array([len(i) for i in single_game])\n",
    "train = np.concatenate(single_game, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(92, 20)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_game[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35913, 20)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final = []\n",
    "for i in range(0, train.shape[1], 2):\n",
    "    final.append(train[:,i:i+2])\n",
    "final = np.concatenate(final, axis=0)\n",
    "seq_lens = np.concatenate([seq_lens for _ in range(10)], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sam/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:58: DeprecationWarning: Class GMM is deprecated; The class GMM is deprecated in 0.18 and will be  removed in 0.20. Use class GaussianMixture instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/home/sam/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:77: DeprecationWarning: Function distribute_covar_matrix_to_match_covariance_type is deprecated; The function distribute_covar_matrix_to_match_covariance_typeis deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/home/sam/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:77: DeprecationWarning: Function distribute_covar_matrix_to_match_covariance_type is deprecated; The function distribute_covar_matrix_to_match_covariance_typeis deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/home/sam/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:77: DeprecationWarning: Function distribute_covar_matrix_to_match_covariance_type is deprecated; The function distribute_covar_matrix_to_match_covariance_typeis deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/home/sam/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:77: DeprecationWarning: Function distribute_covar_matrix_to_match_covariance_type is deprecated; The function distribute_covar_matrix_to_match_covariance_typeis deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/home/sam/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:77: DeprecationWarning: Function distribute_covar_matrix_to_match_covariance_type is deprecated; The function distribute_covar_matrix_to_match_covariance_typeis deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/home/sam/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:77: DeprecationWarning: Function distribute_covar_matrix_to_match_covariance_type is deprecated; The function distribute_covar_matrix_to_match_covariance_typeis deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/home/sam/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:77: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/home/sam/anaconda3/lib/python3.6/site-packages/hmmlearn/base.py:462: DeprecationWarning: `logsumexp` is deprecated!\n",
      "Importing `logsumexp` from scipy.misc is deprecated in scipy 1.0.0. Use `scipy.special.logsumexp` instead.\n",
      "  return logsumexp(fwdlattice[-1]), fwdlattice\n",
      "/home/sam/anaconda3/lib/python3.6/site-packages/hmmlearn/utils.py:46: DeprecationWarning: `logsumexp` is deprecated!\n",
      "Importing `logsumexp` from scipy.misc is deprecated in scipy 1.0.0. Use `scipy.special.logsumexp` instead.\n",
      "  a_lse = logsumexp(a, axis)\n",
      "/home/sam/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:58: DeprecationWarning: Class GMM is deprecated; The class GMM is deprecated in 0.18 and will be  removed in 0.20. Use class GaussianMixture instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "         1    -2795353.5645             +nan\n",
      "         2    -2724411.2842      +70942.2803\n",
      "         3    -2719923.2442       +4488.0400\n",
      "         4    -2716605.7481       +3317.4962\n",
      "         5    -2713868.8269       +2736.9212\n",
      "         6    -2711683.9618       +2184.8651\n",
      "         7    -2709994.5147       +1689.4471\n",
      "         8    -2708676.4359       +1318.0788\n",
      "         9    -2707598.2278       +1078.2081\n",
      "        10    -2706667.6208        +930.6070\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GMMHMM(algorithm='viterbi', covariance_type='diag', covars_prior=0.01,\n",
       "    init_params='stmcw', n_components=6, n_iter=10, n_mix=5,\n",
       "    params='stmcw', random_state=None, startprob_prior=1.0, tol=0.01,\n",
       "    transmat_prior=1.0, verbose=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Viterbi is set by default as the 'algorithm' optional parameter.\n",
    "model = hmm.GMMHMM(n_components=6, n_mix=5, verbose=True)#, covariance_type=\"diag\", n_iter=100) \n",
    "model.fit(final, lengths=seq_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "more than 35913 samples in lengths array [ 92  92 179 ... 140 125 211]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-6ef8c25fad3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstate_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseq_lens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# prob_next_step = model.transmat_[state_sequence[-1], :]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sam/anaconda3/lib/python3.6/site-packages/hmmlearn/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, lengths)\u001b[0m\n\u001b[1;32m    332\u001b[0m             \u001b[0mLabels\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32mfrom\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mX\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \"\"\"\n\u001b[0;32m--> 334\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstate_sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sam/anaconda3/lib/python3.6/site-packages/hmmlearn/base.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, X, lengths, algorithm)\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0mlogprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0mstate_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miter_from_X_lengths\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m             \u001b[0;31m# XXX decoder works on a single sample at a time!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0mlogprobij\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_sequenceij\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sam/anaconda3/lib/python3.6/site-packages/hmmlearn/utils.py\u001b[0m in \u001b[0;36miter_from_X_lengths\u001b[0;34m(X, lengths)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             raise ValueError(\"more than {0:d} samples in lengths array {1!s}\"\n\u001b[0;32m---> 59\u001b[0;31m                              .format(n_samples, lengths))\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: more than 35913 samples in lengths array [ 92  92 179 ... 140 125 211]"
     ]
    }
   ],
   "source": [
    "state_sequence = model.predict(train, lengths=seq_lens)\n",
    "# prob_next_step = model.transmat_[state_sequence[-1], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_lens[:10].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prob_next_step*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "state_sequence.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "state_sequence[:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = -1\n",
    "for i in event_df.moments.values:\n",
    "    for j in i:\n",
    "        m1 = max(np.array(j[5])[:, 3])\n",
    "        if m1>m:\n",
    "            m = m1\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_df.moments.values[0][0][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next: try using the predefined position as indexing mechanism for the imitation learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions:\n",
    "\n",
    "  - Is the latent structure learning trained for each individual agent or their sequences are put together?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
